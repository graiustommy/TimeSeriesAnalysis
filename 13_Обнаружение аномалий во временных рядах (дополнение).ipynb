{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 13. –û–±–Ω–∞—Ä—É–∂–µ–Ω–∏–µ –∞–Ω–æ–º–∞–ª–∏–π –≤–æ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ä—è–¥–∞—Ö\n",
    "\n",
    "## –í–≤–µ–¥–µ–Ω–∏–µ\n",
    "\n",
    "–û–±–Ω–∞—Ä—É–∂–µ–Ω–∏–µ –∞–Ω–æ–º–∞–ª–∏–π (anomaly detection) –≤–æ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ä—è–¥–∞—Ö - —ç—Ç–æ –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏ –≤–∞–∂–Ω–∞—è –∑–∞–¥–∞—á–∞ –≤ –∞–Ω–∞–ª–∏–∑–µ –¥–∞–Ω–Ω—ã—Ö, –∫–æ—Ç–æ—Ä–∞—è –Ω–∞—Ö–æ–¥–∏—Ç –ø—Ä–∏–º–µ–Ω–µ–Ω–∏–µ –≤ —Å–∞–º—ã—Ö —Ä–∞–∑–Ω—ã—Ö –æ–±–ª–∞—Å—Ç—è—Ö: –æ—Ç –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞ –ø—Ä–æ–º—ã—à–ª–µ–Ω–Ω–æ–≥–æ –æ–±–æ—Ä—É–¥–æ–≤–∞–Ω–∏—è –¥–æ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏—è –º–æ—à–µ–Ω–Ω–∏—á–µ—Å–∫–∏—Ö —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–π –∏ –≤—ã—è–≤–ª–µ–Ω–∏—è —Å–±–æ–µ–≤ –≤ IT-—Å–∏—Å—Ç–µ–º–∞—Ö. –ê–Ω–æ–º–∞–ª–∏—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç —Å–æ–±–æ–π –Ω–∞–±–ª—é–¥–µ–Ω–∏–µ, –∫–æ—Ç–æ—Ä–æ–µ –∑–Ω–∞—á–∏—Ç–µ–ª—å–Ω–æ –æ—Ç–ª–∏—á–∞–µ—Ç—Å—è –æ—Ç –æ–±—â–µ–≥–æ –ø–∞—Ç—Ç–µ—Ä–Ω–∞ –¥–∞–Ω–Ω—ã—Ö."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. –¢–µ–æ—Ä–µ—Ç–∏—á–µ—Å–∫–∏–µ –æ—Å–Ω–æ–≤—ã\n",
    "\n",
    "### 1.1 –¢–∏–ø—ã –∞–Ω–æ–º–∞–ª–∏–π –≤–æ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ä—è–¥–∞—Ö\n",
    "\n",
    "**1. –¢–æ—á–µ—á–Ω—ã–µ –∞–Ω–æ–º–∞–ª–∏–∏ (Point Anomalies)**\n",
    "- –û—Ç–¥–µ–ª—å–Ω—ã–µ –Ω–∞–±–ª—é–¥–µ–Ω–∏—è, –∫–æ—Ç–æ—Ä—ã–µ –∑–Ω–∞—á–∏—Ç–µ–ª—å–Ω–æ –æ—Ç–ª–∏—á–∞—é—Ç—Å—è –æ—Ç –æ—Å—Ç–∞–ª—å–Ω—ã—Ö\n",
    "- –ü—Ä–∏–º–µ—Ä: —Ä–µ–∑–∫–∏–π —Å–∫–∞—á–æ–∫ —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä—ã –∏–∑-–∑–∞ –Ω–µ–∏—Å–ø—Ä–∞–≤–Ω–æ—Å—Ç–∏ –¥–∞—Ç—á–∏–∫–∞\n",
    "\n",
    "**2. –ö–æ–Ω—Ç–µ–∫—Å—Ç—É–∞–ª—å–Ω—ã–µ –∞–Ω–æ–º–∞–ª–∏–∏ (Contextual Anomalies)**\n",
    "- –ó–Ω–∞—á–µ–Ω–∏—è, –∞–Ω–æ–º–∞–ª—å–Ω—ã–µ –≤ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω–æ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ\n",
    "- –ü—Ä–∏–º–µ—Ä: –≤—ã—Å–æ–∫–∞—è —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞ –∑–∏–º–æ–π –∏–ª–∏ –Ω–∏–∑–∫–∞—è –ª–µ—Ç–æ–º\n",
    "\n",
    "**3. –ö–æ–ª–ª–µ–∫—Ç–∏–≤–Ω—ã–µ –∞–Ω–æ–º–∞–ª–∏–∏ (Collective Anomalies)**\n",
    "- –ü–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å –Ω–∞–±–ª—é–¥–µ–Ω–∏–π, –∫–æ—Ç–æ—Ä—ã–µ –≤–º–µ—Å—Ç–µ –æ–±—Ä–∞–∑—É—é—Ç –∞–Ω–æ–º–∞–ª—å–Ω—ã–π –ø–∞—Ç—Ç–µ—Ä–Ω\n",
    "- –ü—Ä–∏–º–µ—Ä: –ø–æ—Å—Ç–µ–ø–µ–Ω–Ω–∞—è –¥–µ–≥—Ä–∞–¥–∞—Ü–∏—è –æ–±–æ—Ä—É–¥–æ–≤–∞–Ω–∏—è\n",
    "\n",
    "### 1.2 –û—Å–Ω–æ–≤–Ω—ã–µ –ø–æ–¥—Ö–æ–¥—ã –∫ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏—é –∞–Ω–æ–º–∞–ª–∏–π\n",
    "\n",
    "**1. –°—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∏–µ –º–µ—Ç–æ–¥—ã**\n",
    "- Z-score (—Å—Ç–∞–Ω–¥–∞—Ä—Ç–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –æ—Å—Ç–∞—Ç–∫–∏)\n",
    "- –ú–µ–∂–∫–≤–∞—Ä—Ç–∏–ª—å–Ω—ã–π —Ä–∞–∑–º–∞—Ö (IQR)\n",
    "- –¢–µ—Å—Ç—ã –Ω–∞ –≤—ã–±—Ä–æ—Å—ã (Grubbs, Dixon)\n",
    "\n",
    "**2. –ú–µ—Ç–æ–¥—ã –º–∞—à–∏–Ω–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è**\n",
    "- Isolation Forest\n",
    "- Local Outlier Factor (LOF)\n",
    "- One-Class SVM\n",
    "- Autoencoder-based methods\n",
    "\n",
    "**3. –ú–µ—Ç–æ–¥—ã –Ω–∞ –æ—Å–Ω–æ–≤–µ –ø—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏—è**\n",
    "- ARIMA residuals\n",
    "- LSTM prediction errors\n",
    "- Prophet anomaly detection\n",
    "\n",
    "**4. –ú–µ—Ç–æ–¥—ã –¥–µ–∫–æ–º–ø–æ–∑–∏—Ü–∏–∏**\n",
    "- STL (Seasonal and Trend decomposition using Loess)\n",
    "- Twitter's AnomalyDetection\n",
    "\n",
    "### 1.3 –ú–µ—Ç—Ä–∏–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞\n",
    "\n",
    "–î–ª—è –æ—Ü–µ–Ω–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏—è –∞–Ω–æ–º–∞–ª–∏–π –∏—Å–ø–æ–ª—å–∑—É—é—Ç—Å—è:\n",
    "\n",
    "- **Precision (–¢–æ—á–Ω–æ—Å—Ç—å)**: $\\frac{TP}{TP + FP}$ - –¥–æ–ª—è –ø—Ä–∞–≤–∏–ª—å–Ω–æ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–Ω—ã—Ö –∞–Ω–æ–º–∞–ª–∏–π —Å—Ä–µ–¥–∏ –≤—Å–µ—Ö –æ–±–Ω–∞—Ä—É–∂–µ–Ω–Ω—ã—Ö\n",
    "- **Recall (–ü–æ–ª–Ω–æ—Ç–∞)**: $\\frac{TP}{TP + FN}$ - –¥–æ–ª—è –æ–±–Ω–∞—Ä—É–∂–µ–Ω–Ω—ã—Ö –∞–Ω–æ–º–∞–ª–∏–π —Å—Ä–µ–¥–∏ –≤—Å–µ—Ö —Ä–µ–∞–ª—å–Ω—ã—Ö –∞–Ω–æ–º–∞–ª–∏–π\n",
    "- **F1-Score**: $2 \\cdot \\frac{Precision \\cdot Recall}{Precision + Recall}$ - –≥–∞—Ä–º–æ–Ω–∏—á–µ—Å–∫–æ–µ —Å—Ä–µ–¥–Ω–µ–µ precision –∏ recall\n",
    "- **ROC-AUC**: –ø–ª–æ—â–∞–¥—å –ø–æ–¥ ROC-–∫—Ä–∏–≤–æ–π\n",
    "\n",
    "–≥–¥–µ:\n",
    "- TP (True Positive) - –ø—Ä–∞–≤–∏–ª—å–Ω–æ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–Ω—ã–µ –∞–Ω–æ–º–∞–ª–∏–∏\n",
    "- FP (False Positive) - –ª–æ–∂–Ω—ã–µ —Å—Ä–∞–±–∞—Ç—ã–≤–∞–Ω–∏—è\n",
    "- FN (False Negative) - –ø—Ä–æ–ø—É—â–µ–Ω–Ω—ã–µ –∞–Ω–æ–º–∞–ª–∏–∏"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. –ü—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∞—è —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—è\n",
    "\n",
    "### 2.1 –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö –∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –∞–Ω–æ–º–∞–ª–∏–π"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "from sklearn.svm import OneClassSVM\n",
    "from sklearn.metrics import confusion_matrix, classification_report, roc_auc_score, roc_curve\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "plt.rcParams['figure.figsize'] = (14, 6)\n",
    "\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Å–∏–Ω—Ç–µ—Ç–∏—á–µ—Å–∫–æ–≥–æ –≤—Ä–µ–º–µ–Ω–Ω–æ–≥–æ —Ä—è–¥–∞ —Å –∞–Ω–æ–º–∞–ª–∏—è–º–∏\n",
    "def generate_ts_with_anomalies(n_points=1000, anomaly_ratio=0.05):\n",
    "    \"\"\"\n",
    "    –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –≤—Ä–µ–º–µ–Ω–Ω–æ–≥–æ —Ä—è–¥–∞ —Å —Ä–∞–∑–ª–∏—á–Ω—ã–º–∏ —Ç–∏–ø–∞–º–∏ –∞–Ω–æ–º–∞–ª–∏–π\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    n_points : int\n",
    "        –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç–æ—á–µ–∫\n",
    "    anomaly_ratio : float\n",
    "        –î–æ–ª—è –∞–Ω–æ–º–∞–ª–∏–π –≤ –¥–∞–Ω–Ω—ã—Ö\n",
    "    \"\"\"\n",
    "    time = np.arange(n_points)\n",
    "    \n",
    "    # –û—Å–Ω–æ–≤–Ω—ã–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã —Ä—è–¥–∞\n",
    "    trend = 0.01 * time\n",
    "    seasonality = 5 * np.sin(2 * np.pi * time / 50) + 3 * np.sin(2 * np.pi * time / 100)\n",
    "    noise = np.random.randn(n_points) * 0.5\n",
    "    \n",
    "    # –ù–æ—Ä–º–∞–ª—å–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è\n",
    "    ts = trend + seasonality + noise + 20\n",
    "    \n",
    "    # –î–æ–±–∞–≤–ª–µ–Ω–∏–µ –∞–Ω–æ–º–∞–ª–∏–π\n",
    "    n_anomalies = int(n_points * anomaly_ratio)\n",
    "    anomaly_indices = np.random.choice(n_points, n_anomalies, replace=False)\n",
    "    \n",
    "    # –ú–µ—Ç–∫–∏: 1 - –Ω–æ—Ä–º–∞–ª—å–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ, -1 - –∞–Ω–æ–º–∞–ª–∏—è\n",
    "    labels = np.ones(n_points)\n",
    "    labels[anomaly_indices] = -1\n",
    "    \n",
    "    # –¢–∏–ø—ã –∞–Ω–æ–º–∞–ª–∏–π\n",
    "    for idx in anomaly_indices:\n",
    "        anomaly_type = np.random.choice(['spike', 'drop', 'shift'])\n",
    "        \n",
    "        if anomaly_type == 'spike':\n",
    "            # –†–µ–∑–∫–∏–π —Å–∫–∞—á–æ–∫ –≤–≤–µ—Ä—Ö\n",
    "            ts[idx] += np.random.uniform(10, 20)\n",
    "        elif anomaly_type == 'drop':\n",
    "            # –†–µ–∑–∫–æ–µ –ø–∞–¥–µ–Ω–∏–µ\n",
    "            ts[idx] -= np.random.uniform(10, 20)\n",
    "        elif anomaly_type == 'shift' and idx < n_points - 10:\n",
    "            # –°–¥–≤–∏–≥ —É—Ä–æ–≤–Ω—è\n",
    "            shift_length = min(10, n_points - idx)\n",
    "            ts[idx:idx + shift_length] += np.random.uniform(5, 10)\n",
    "    \n",
    "    df = pd.DataFrame({\n",
    "        'time': time,\n",
    "        'value': ts,\n",
    "        'is_anomaly': (labels == -1).astype(int)\n",
    "    })\n",
    "    \n",
    "    return df\n",
    "\n",
    "# –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö\n",
    "df = generate_ts_with_anomalies(n_points=1000, anomaly_ratio=0.05)\n",
    "\n",
    "# –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è\n",
    "fig, ax = plt.subplots(figsize=(16, 6))\n",
    "ax.plot(df['time'], df['value'], label='–í—Ä–µ–º–µ–Ω–Ω–æ–π —Ä—è–¥', alpha=0.7, linewidth=1)\n",
    "anomalies = df[df['is_anomaly'] == 1]\n",
    "ax.scatter(anomalies['time'], anomalies['value'], \n",
    "           color='red', s=100, label='–ê–Ω–æ–º–∞–ª–∏–∏', zorder=5, alpha=0.7)\n",
    "ax.set_xlabel('–í—Ä–µ–º—è')\n",
    "ax.set_ylabel('–ó–Ω–∞—á–µ–Ω–∏–µ')\n",
    "ax.set_title('–í—Ä–µ–º–µ–Ω–Ω–æ–π —Ä—è–¥ —Å –∞–Ω–æ–º–∞–ª–∏—è–º–∏')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"–í—Å–µ–≥–æ —Ç–æ—á–µ–∫: {len(df)}\")\n",
    "print(f\"–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∞–Ω–æ–º–∞–ª–∏–π: {df['is_anomaly'].sum()}\")\n",
    "print(f\"–ü—Ä–æ—Ü–µ–Ω—Ç –∞–Ω–æ–º–∞–ª–∏–π: {df['is_anomaly'].mean() * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 –°—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∏–µ –º–µ—Ç–æ–¥—ã\n",
    "\n",
    "### 2.2.1 Z-score –º–µ—Ç–æ–¥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_anomalies_zscore(data, threshold=3):\n",
    "    \"\"\"\n",
    "    –û–±–Ω–∞—Ä—É–∂–µ–Ω–∏–µ –∞–Ω–æ–º–∞–ª–∏–π –º–µ—Ç–æ–¥–æ–º Z-score\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    data : array-like\n",
    "        –í—Ä–µ–º–µ–Ω–Ω–æ–π —Ä—è–¥\n",
    "    threshold : float\n",
    "        –ü–æ—Ä–æ–≥ –¥–ª—è Z-score (–æ–±—ã—á–Ω–æ 2-3)\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    anomalies : array\n",
    "        –ë—É–ª–µ–≤ –º–∞—Å—Å–∏–≤ —Å –º–µ—Ç–∫–∞–º–∏ –∞–Ω–æ–º–∞–ª–∏–π\n",
    "    z_scores : array\n",
    "        Z-scores –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –Ω–∞–±–ª—é–¥–µ–Ω–∏—è\n",
    "    \"\"\"\n",
    "    mean = np.mean(data)\n",
    "    std = np.std(data)\n",
    "    z_scores = np.abs((data - mean) / std)\n",
    "    anomalies = z_scores > threshold\n",
    "    return anomalies, z_scores\n",
    "\n",
    "# –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ Z-score –º–µ—Ç–æ–¥–∞\n",
    "anomalies_zscore, z_scores = detect_anomalies_zscore(df['value'].values, threshold=3)\n",
    "\n",
    "# –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è\n",
    "fig, axes = plt.subplots(2, 1, figsize=(16, 10))\n",
    "\n",
    "# –ì—Ä–∞—Ñ–∏–∫ –≤—Ä–µ–º–µ–Ω–Ω–æ–≥–æ —Ä—è–¥–∞ —Å –æ–±–Ω–∞—Ä—É–∂–µ–Ω–Ω—ã–º–∏ –∞–Ω–æ–º–∞–ª–∏—è–º–∏\n",
    "axes[0].plot(df['time'], df['value'], label='–í—Ä–µ–º–µ–Ω–Ω–æ–π —Ä—è–¥', alpha=0.7)\n",
    "detected = df[anomalies_zscore]\n",
    "axes[0].scatter(detected['time'], detected['value'], \n",
    "                color='red', s=100, label='–û–±–Ω–∞—Ä—É–∂–µ–Ω–Ω—ã–µ –∞–Ω–æ–º–∞–ª–∏–∏ (Z-score)', zorder=5)\n",
    "true_anomalies = df[df['is_anomaly'] == 1]\n",
    "axes[0].scatter(true_anomalies['time'], true_anomalies['value'], \n",
    "                color='orange', s=50, marker='x', label='–ò—Å—Ç–∏–Ω–Ω—ã–µ –∞–Ω–æ–º–∞–ª–∏–∏', zorder=4)\n",
    "axes[0].set_xlabel('–í—Ä–µ–º—è')\n",
    "axes[0].set_ylabel('–ó–Ω–∞—á–µ–Ω–∏–µ')\n",
    "axes[0].set_title('–û–±–Ω–∞—Ä—É–∂–µ–Ω–∏–µ –∞–Ω–æ–º–∞–ª–∏–π –º–µ—Ç–æ–¥–æ–º Z-score')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# –ì—Ä–∞—Ñ–∏–∫ Z-scores\n",
    "axes[1].plot(df['time'], z_scores, label='Z-scores', color='blue', alpha=0.7)\n",
    "axes[1].axhline(y=3, color='red', linestyle='--', label='–ü–æ—Ä–æ–≥ (threshold=3)')\n",
    "axes[1].fill_between(df['time'], 0, z_scores, where=anomalies_zscore, \n",
    "                      color='red', alpha=0.3, label='–ê–Ω–æ–º–∞–ª—å–Ω–∞—è –∑–æ–Ω–∞')\n",
    "axes[1].set_xlabel('–í—Ä–µ–º—è')\n",
    "axes[1].set_ylabel('Z-score')\n",
    "axes[1].set_title('Z-scores –≤—Ä–µ–º–µ–Ω–Ω–æ–≥–æ —Ä—è–¥–∞')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# –û—Ü–µ–Ω–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "y_true = df['is_anomaly'].values\n",
    "y_pred = anomalies_zscore.astype(int)\n",
    "\n",
    "print(\"\\n–ú–µ—Ç—Ä–∏–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞ Z-score –º–µ—Ç–æ–¥–∞:\")\n",
    "print(f\"Precision: {precision_score(y_true, y_pred):.3f}\")\n",
    "print(f\"Recall: {recall_score(y_true, y_pred):.3f}\")\n",
    "print(f\"F1-Score: {f1_score(y_true, y_pred):.3f}\")\n",
    "print(f\"\\n–û–±–Ω–∞—Ä—É–∂–µ–Ω–æ –∞–Ω–æ–º–∞–ª–∏–π: {y_pred.sum()}\")\n",
    "print(f\"–ò—Å—Ç–∏–Ω–Ω—ã—Ö –∞–Ω–æ–º–∞–ª–∏–π: {y_true.sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.2 IQR (Interquartile Range) –º–µ—Ç–æ–¥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_anomalies_iqr(data, k=1.5):\n",
    "    \"\"\"\n",
    "    –û–±–Ω–∞—Ä—É–∂–µ–Ω–∏–µ –∞–Ω–æ–º–∞–ª–∏–π –º–µ—Ç–æ–¥–æ–º IQR\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    data : array-like\n",
    "        –í—Ä–µ–º–µ–Ω–Ω–æ–π —Ä—è–¥\n",
    "    k : float\n",
    "        –ö–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç –¥–ª—è —Ä–∞—Å—á–µ—Ç–∞ –≥—Ä–∞–Ω–∏—Ü (–æ–±—ã—á–Ω–æ 1.5)\n",
    "    \"\"\"\n",
    "    Q1 = np.percentile(data, 25)\n",
    "    Q3 = np.percentile(data, 75)\n",
    "    IQR = Q3 - Q1\n",
    "    \n",
    "    lower_bound = Q1 - k * IQR\n",
    "    upper_bound = Q3 + k * IQR\n",
    "    \n",
    "    anomalies = (data < lower_bound) | (data > upper_bound)\n",
    "    \n",
    "    return anomalies, lower_bound, upper_bound\n",
    "\n",
    "# –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ IQR –º–µ—Ç–æ–¥–∞\n",
    "anomalies_iqr, lower_bound, upper_bound = detect_anomalies_iqr(df['value'].values, k=1.5)\n",
    "\n",
    "# –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è\n",
    "plt.figure(figsize=(16, 6))\n",
    "plt.plot(df['time'], df['value'], label='–í—Ä–µ–º–µ–Ω–Ω–æ–π —Ä—è–¥', alpha=0.7)\n",
    "plt.axhline(y=lower_bound, color='green', linestyle='--', label=f'–ù–∏–∂–Ω—è—è –≥—Ä–∞–Ω–∏—Ü–∞ ({lower_bound:.2f})')\n",
    "plt.axhline(y=upper_bound, color='green', linestyle='--', label=f'–í–µ—Ä—Ö–Ω—è—è –≥—Ä–∞–Ω–∏—Ü–∞ ({upper_bound:.2f})')\n",
    "plt.fill_between(df['time'], lower_bound, upper_bound, alpha=0.2, color='green', label='–ù–æ—Ä–º–∞–ª—å–Ω—ã–π –¥–∏–∞–ø–∞–∑–æ–Ω')\n",
    "\n",
    "detected_iqr = df[anomalies_iqr]\n",
    "plt.scatter(detected_iqr['time'], detected_iqr['value'], \n",
    "            color='red', s=100, label='–û–±–Ω–∞—Ä—É–∂–µ–Ω–Ω—ã–µ –∞–Ω–æ–º–∞–ª–∏–∏ (IQR)', zorder=5)\n",
    "\n",
    "plt.xlabel('–í—Ä–µ–º—è')\n",
    "plt.ylabel('–ó–Ω–∞—á–µ–Ω–∏–µ')\n",
    "plt.title('–û–±–Ω–∞—Ä—É–∂–µ–Ω–∏–µ –∞–Ω–æ–º–∞–ª–∏–π –º–µ—Ç–æ–¥–æ–º IQR')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# –ú–µ—Ç—Ä–∏–∫–∏\n",
    "y_pred_iqr = anomalies_iqr.astype(int)\n",
    "print(\"\\n–ú–µ—Ç—Ä–∏–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞ IQR –º–µ—Ç–æ–¥–∞:\")\n",
    "print(f\"Precision: {precision_score(y_true, y_pred_iqr):.3f}\")\n",
    "print(f\"Recall: {recall_score(y_true, y_pred_iqr):.3f}\")\n",
    "print(f\"F1-Score: {f1_score(y_true, y_pred_iqr):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.3 –°–∫–æ–ª—å–∑—è—â–µ–µ —Å—Ä–µ–¥–Ω–µ–µ –∏ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–µ –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏–µ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_anomalies_moving_average(data, window=20, n_std=2):\n",
    "    \"\"\"\n",
    "    –û–±–Ω–∞—Ä—É–∂–µ–Ω–∏–µ –∞–Ω–æ–º–∞–ª–∏–π –Ω–∞ –æ—Å–Ω–æ–≤–µ —Å–∫–æ–ª—å–∑—è—â–µ–≥–æ —Å—Ä–µ–¥–Ω–µ–≥–æ\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    data : array-like\n",
    "        –í—Ä–µ–º–µ–Ω–Ω–æ–π —Ä—è–¥\n",
    "    window : int\n",
    "        –†–∞–∑–º–µ—Ä –æ–∫–Ω–∞ –¥–ª—è —Å–∫–æ–ª—å–∑—è—â–µ–≥–æ —Å—Ä–µ–¥–Ω–µ–≥–æ\n",
    "    n_std : float\n",
    "        –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã—Ö –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏–π –¥–ª—è –ø–æ—Ä–æ–≥–∞\n",
    "    \"\"\"\n",
    "    rolling_mean = pd.Series(data).rolling(window=window, center=True).mean()\n",
    "    rolling_std = pd.Series(data).rolling(window=window, center=True).std()\n",
    "    \n",
    "    upper_bound = rolling_mean + n_std * rolling_std\n",
    "    lower_bound = rolling_mean - n_std * rolling_std\n",
    "    \n",
    "    anomalies = (data > upper_bound) | (data < lower_bound)\n",
    "    \n",
    "    return anomalies, rolling_mean, upper_bound, lower_bound\n",
    "\n",
    "# –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ –º–µ—Ç–æ–¥–∞ —Å–∫–æ–ª—å–∑—è—â–µ–≥–æ —Å—Ä–µ–¥–Ω–µ–≥–æ\n",
    "anomalies_ma, rolling_mean, upper_bound_ma, lower_bound_ma = \\\n",
    "    detect_anomalies_moving_average(df['value'].values, window=50, n_std=2.5)\n",
    "\n",
    "# –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è\n",
    "plt.figure(figsize=(16, 6))\n",
    "plt.plot(df['time'], df['value'], label='–í—Ä–µ–º–µ–Ω–Ω–æ–π —Ä—è–¥', alpha=0.6, linewidth=1)\n",
    "plt.plot(df['time'], rolling_mean, label='–°–∫–æ–ª—å–∑—è—â–µ–µ —Å—Ä–µ–¥–Ω–µ–µ', color='blue', linewidth=2)\n",
    "plt.plot(df['time'], upper_bound_ma, '--', label='–í–µ—Ä—Ö–Ω—è—è –≥—Ä–∞–Ω–∏—Ü–∞', color='green', linewidth=1.5)\n",
    "plt.plot(df['time'], lower_bound_ma, '--', label='–ù–∏–∂–Ω—è—è –≥—Ä–∞–Ω–∏—Ü–∞', color='green', linewidth=1.5)\n",
    "plt.fill_between(df['time'], lower_bound_ma, upper_bound_ma, alpha=0.2, color='green')\n",
    "\n",
    "detected_ma = df[anomalies_ma]\n",
    "plt.scatter(detected_ma['time'], detected_ma['value'], \n",
    "            color='red', s=100, label='–û–±–Ω–∞—Ä—É–∂–µ–Ω–Ω—ã–µ –∞–Ω–æ–º–∞–ª–∏–∏', zorder=5)\n",
    "\n",
    "plt.xlabel('–í—Ä–µ–º—è')\n",
    "plt.ylabel('–ó–Ω–∞—á–µ–Ω–∏–µ')\n",
    "plt.title('–û–±–Ω–∞—Ä—É–∂–µ–Ω–∏–µ –∞–Ω–æ–º–∞–ª–∏–π –º–µ—Ç–æ–¥–æ–º —Å–∫–æ–ª—å–∑—è—â–µ–≥–æ —Å—Ä–µ–¥–Ω–µ–≥–æ')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# –ú–µ—Ç—Ä–∏–∫–∏\n",
    "y_pred_ma = anomalies_ma.astype(int)\n",
    "print(\"\\n–ú–µ—Ç—Ä–∏–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞ –º–µ—Ç–æ–¥–∞ —Å–∫–æ–ª—å–∑—è—â–µ–≥–æ —Å—Ä–µ–¥–Ω–µ–≥–æ:\")\n",
    "print(f\"Precision: {precision_score(y_true, y_pred_ma):.3f}\")\n",
    "print(f\"Recall: {recall_score(y_true, y_pred_ma):.3f}\")\n",
    "print(f\"F1-Score: {f1_score(y_true, y_pred_ma):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 –ú–µ—Ç–æ–¥—ã –º–∞—à–∏–Ω–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è\n",
    "\n",
    "### 2.3.1 Isolation Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤\n",
    "def create_features(df, window=10):\n",
    "    \"\"\"\n",
    "    –°–æ–∑–¥–∞–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –¥–ª—è ML –º–æ–¥–µ–ª–µ–π\n",
    "    \"\"\"\n",
    "    features = pd.DataFrame()\n",
    "    features['value'] = df['value']\n",
    "    \n",
    "    # –°–∫–æ–ª—å–∑—è—â–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏\n",
    "    features['rolling_mean'] = df['value'].rolling(window=window, center=True).mean()\n",
    "    features['rolling_std'] = df['value'].rolling(window=window, center=True).std()\n",
    "    features['rolling_min'] = df['value'].rolling(window=window, center=True).min()\n",
    "    features['rolling_max'] = df['value'].rolling(window=window, center=True).max()\n",
    "    \n",
    "    # –†–∞–∑–Ω–æ—Å—Ç–∏\n",
    "    features['diff_1'] = df['value'].diff(1)\n",
    "    features['diff_2'] = df['value'].diff(2)\n",
    "    \n",
    "    # –õ–∞–≥–∏\n",
    "    features['lag_1'] = df['value'].shift(1)\n",
    "    features['lag_2'] = df['value'].shift(2)\n",
    "    \n",
    "    # –ó–∞–ø–æ–ª–Ω–µ–Ω–∏–µ –ø—Ä–æ–ø—É—Å–∫–æ–≤\n",
    "    features = features.fillna(method='bfill').fillna(method='ffill')\n",
    "    \n",
    "    return features\n",
    "\n",
    "# –°–æ–∑–¥–∞–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤\n",
    "X = create_features(df, window=20)\n",
    "\n",
    "# –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Isolation Forest\n",
    "iso_forest = IsolationForest(\n",
    "    contamination=0.05,  # –æ–∂–∏–¥–∞–µ–º–∞—è –¥–æ–ª—è –∞–Ω–æ–º–∞–ª–∏–π\n",
    "    random_state=42,\n",
    "    n_estimators=100\n",
    ")\n",
    "\n",
    "# –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ: -1 –¥–ª—è –∞–Ω–æ–º–∞–ª–∏–π, 1 –¥–ª—è –Ω–æ—Ä–º–∞–ª—å–Ω—ã—Ö —Ç–æ—á–µ–∫\n",
    "predictions_if = iso_forest.fit_predict(X_scaled)\n",
    "anomaly_scores_if = iso_forest.score_samples(X_scaled)\n",
    "\n",
    "# –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è\n",
    "fig, axes = plt.subplots(2, 1, figsize=(16, 10))\n",
    "\n",
    "# –ì—Ä–∞—Ñ–∏–∫ –≤—Ä–µ–º–µ–Ω–Ω–æ–≥–æ —Ä—è–¥–∞\n",
    "axes[0].plot(df['time'], df['value'], label='–í—Ä–µ–º–µ–Ω–Ω–æ–π —Ä—è–¥', alpha=0.7)\n",
    "anomalies_if = df[predictions_if == -1]\n",
    "axes[0].scatter(anomalies_if['time'], anomalies_if['value'], \n",
    "                color='red', s=100, label='–û–±–Ω–∞—Ä—É–∂–µ–Ω–Ω—ã–µ –∞–Ω–æ–º–∞–ª–∏–∏ (Isolation Forest)', zorder=5)\n",
    "true_anomalies = df[df['is_anomaly'] == 1]\n",
    "axes[0].scatter(true_anomalies['time'], true_anomalies['value'], \n",
    "                color='orange', s=50, marker='x', label='–ò—Å—Ç–∏–Ω–Ω—ã–µ –∞–Ω–æ–º–∞–ª–∏–∏', zorder=4)\n",
    "axes[0].set_xlabel('–í—Ä–µ–º—è')\n",
    "axes[0].set_ylabel('–ó–Ω–∞—á–µ–Ω–∏–µ')\n",
    "axes[0].set_title('–û–±–Ω–∞—Ä—É–∂–µ–Ω–∏–µ –∞–Ω–æ–º–∞–ª–∏–π —Å –ø–æ–º–æ—â—å—é Isolation Forest')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# –ì—Ä–∞—Ñ–∏–∫ –∞–Ω–æ–º–∞–ª—å–Ω—ã—Ö —Å–∫–æ—Ä–æ–≤\n",
    "axes[1].plot(df['time'], anomaly_scores_if, label='Anomaly Score', color='purple', alpha=0.7)\n",
    "axes[1].fill_between(df['time'], anomaly_scores_if, \n",
    "                     where=(predictions_if == -1), color='red', alpha=0.3, label='–ê–Ω–æ–º–∞–ª–∏–∏')\n",
    "axes[1].set_xlabel('–í—Ä–µ–º—è')\n",
    "axes[1].set_ylabel('Anomaly Score')\n",
    "axes[1].set_title('Anomaly Scores –æ—Ç Isolation Forest (–±–æ–ª–µ–µ –æ—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω—ã–µ = –±–æ–ª–µ–µ –∞–Ω–æ–º–∞–ª—å–Ω—ã–µ)')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# –ú–µ—Ç—Ä–∏–∫–∏\n",
    "y_pred_if = (predictions_if == -1).astype(int)\n",
    "print(\"\\n–ú–µ—Ç—Ä–∏–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞ Isolation Forest:\")\n",
    "print(f\"Precision: {precision_score(y_true, y_pred_if):.3f}\")\n",
    "print(f\"Recall: {recall_score(y_true, y_pred_if):.3f}\")\n",
    "print(f\"F1-Score: {f1_score(y_true, y_pred_if):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.2 Local Outlier Factor (LOF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Local Outlier Factor\n",
    "lof = LocalOutlierFactor(\n",
    "    n_neighbors=20,\n",
    "    contamination=0.05,\n",
    "    novelty=False\n",
    ")\n",
    "\n",
    "predictions_lof = lof.fit_predict(X_scaled)\n",
    "anomaly_scores_lof = lof.negative_outlier_factor_\n",
    "\n",
    "# –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è\n",
    "fig, axes = plt.subplots(2, 1, figsize=(16, 10))\n",
    "\n",
    "axes[0].plot(df['time'], df['value'], label='–í—Ä–µ–º–µ–Ω–Ω–æ–π —Ä—è–¥', alpha=0.7)\n",
    "anomalies_lof = df[predictions_lof == -1]\n",
    "axes[0].scatter(anomalies_lof['time'], anomalies_lof['value'], \n",
    "                color='red', s=100, label='–û–±–Ω–∞—Ä—É–∂–µ–Ω–Ω—ã–µ –∞–Ω–æ–º–∞–ª–∏–∏ (LOF)', zorder=5)\n",
    "axes[0].scatter(true_anomalies['time'], true_anomalies['value'], \n",
    "                color='orange', s=50, marker='x', label='–ò—Å—Ç–∏–Ω–Ω—ã–µ –∞–Ω–æ–º–∞–ª–∏–∏', zorder=4)\n",
    "axes[0].set_xlabel('–í—Ä–µ–º—è')\n",
    "axes[0].set_ylabel('–ó–Ω–∞—á–µ–Ω–∏–µ')\n",
    "axes[0].set_title('–û–±–Ω–∞—Ä—É–∂–µ–Ω–∏–µ –∞–Ω–æ–º–∞–ª–∏–π —Å –ø–æ–º–æ—â—å—é Local Outlier Factor')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "axes[1].plot(df['time'], anomaly_scores_lof, label='LOF Score', color='purple', alpha=0.7)\n",
    "axes[1].fill_between(df['time'], anomaly_scores_lof, \n",
    "                     where=(predictions_lof == -1), color='red', alpha=0.3, label='–ê–Ω–æ–º–∞–ª–∏–∏')\n",
    "axes[1].set_xlabel('–í—Ä–µ–º—è')\n",
    "axes[1].set_ylabel('LOF Score')\n",
    "axes[1].set_title('LOF Scores (–±–æ–ª–µ–µ –æ—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω—ã–µ = –±–æ–ª–µ–µ –∞–Ω–æ–º–∞–ª—å–Ω—ã–µ)')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# –ú–µ—Ç—Ä–∏–∫–∏\n",
    "y_pred_lof = (predictions_lof == -1).astype(int)\n",
    "print(\"\\n–ú–µ—Ç—Ä–∏–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞ LOF:\")\n",
    "print(f\"Precision: {precision_score(y_true, y_pred_lof):.3f}\")\n",
    "print(f\"Recall: {recall_score(y_true, y_pred_lof):.3f}\")\n",
    "print(f\"F1-Score: {f1_score(y_true, y_pred_lof):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.3 One-Class SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-Class SVM\n",
    "oc_svm = OneClassSVM(\n",
    "    kernel='rbf',\n",
    "    gamma='auto',\n",
    "    nu=0.05  # –≤–µ—Ä—Ö–Ω—è—è –≥—Ä–∞–Ω–∏—Ü–∞ –¥–æ–ª–∏ –∞–Ω–æ–º–∞–ª–∏–π\n",
    ")\n",
    "\n",
    "predictions_svm = oc_svm.fit_predict(X_scaled)\n",
    "anomaly_scores_svm = oc_svm.score_samples(X_scaled)\n",
    "\n",
    "# –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è\n",
    "plt.figure(figsize=(16, 6))\n",
    "plt.plot(df['time'], df['value'], label='–í—Ä–µ–º–µ–Ω–Ω–æ–π —Ä—è–¥', alpha=0.7)\n",
    "anomalies_svm = df[predictions_svm == -1]\n",
    "plt.scatter(anomalies_svm['time'], anomalies_svm['value'], \n",
    "            color='red', s=100, label='–û–±–Ω–∞—Ä—É–∂–µ–Ω–Ω—ã–µ –∞–Ω–æ–º–∞–ª–∏–∏ (One-Class SVM)', zorder=5)\n",
    "plt.scatter(true_anomalies['time'], true_anomalies['value'], \n",
    "            color='orange', s=50, marker='x', label='–ò—Å—Ç–∏–Ω–Ω—ã–µ –∞–Ω–æ–º–∞–ª–∏–∏', zorder=4)\n",
    "plt.xlabel('–í—Ä–µ–º—è')\n",
    "plt.ylabel('–ó–Ω–∞—á–µ–Ω–∏–µ')\n",
    "plt.title('–û–±–Ω–∞—Ä—É–∂–µ–Ω–∏–µ –∞–Ω–æ–º–∞–ª–∏–π —Å –ø–æ–º–æ—â—å—é One-Class SVM')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# –ú–µ—Ç—Ä–∏–∫–∏\n",
    "y_pred_svm = (predictions_svm == -1).astype(int)\n",
    "print(\"\\n–ú–µ—Ç—Ä–∏–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞ One-Class SVM:\")\n",
    "print(f\"Precision: {precision_score(y_true, y_pred_svm):.3f}\")\n",
    "print(f\"Recall: {recall_score(y_true, y_pred_svm):.3f}\")\n",
    "print(f\"F1-Score: {f1_score(y_true, y_pred_svm):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4 –ú–µ—Ç–æ–¥—ã –Ω–∞ –æ—Å–Ω–æ–≤–µ –ø—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏—è\n",
    "\n",
    "### 2.4.1 ARIMA residuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "\n",
    "# –û–±—É—á–µ–Ω–∏–µ ARIMA –º–æ–¥–µ–ª–∏\n",
    "model_arima = ARIMA(df['value'], order=(2, 1, 2))\n",
    "fitted_arima = model_arima.fit()\n",
    "\n",
    "# –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –∏ –æ—Å—Ç–∞—Ç–∫–∏\n",
    "predictions_arima = fitted_arima.fittedvalues\n",
    "residuals = df['value'] - predictions_arima\n",
    "\n",
    "# –û–±–Ω–∞—Ä—É–∂–µ–Ω–∏–µ –∞–Ω–æ–º–∞–ª–∏–π –ø–æ –æ—Å—Ç–∞—Ç–∫–∞–º (–∏—Å–ø–æ–ª—å–∑—É–µ–º Z-score)\n",
    "threshold_residuals = 3\n",
    "residuals_zscore = np.abs((residuals - residuals.mean()) / residuals.std())\n",
    "anomalies_arima = residuals_zscore > threshold_residuals\n",
    "\n",
    "# –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è\n",
    "fig, axes = plt.subplots(3, 1, figsize=(16, 12))\n",
    "\n",
    "# –ò—Å—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –∏ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è\n",
    "axes[0].plot(df['time'], df['value'], label='–ò—Å—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ', alpha=0.7)\n",
    "axes[0].plot(df['time'], predictions_arima, label='ARIMA –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è', alpha=0.7, linestyle='--')\n",
    "detected_arima = df[anomalies_arima]\n",
    "axes[0].scatter(detected_arima['time'], detected_arima['value'], \n",
    "                color='red', s=100, label='–û–±–Ω–∞—Ä—É–∂–µ–Ω–Ω—ã–µ –∞–Ω–æ–º–∞–ª–∏–∏', zorder=5)\n",
    "axes[0].set_xlabel('–í—Ä–µ–º—è')\n",
    "axes[0].set_ylabel('–ó–Ω–∞—á–µ–Ω–∏–µ')\n",
    "axes[0].set_title('ARIMA –º–æ–¥–µ–ª—å –∏ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–Ω—ã–µ –∞–Ω–æ–º–∞–ª–∏–∏')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# –û—Å—Ç–∞—Ç–∫–∏\n",
    "axes[1].plot(df['time'], residuals, label='–û—Å—Ç–∞—Ç–∫–∏', alpha=0.7, color='green')\n",
    "axes[1].axhline(y=0, color='black', linestyle='-', linewidth=1)\n",
    "axes[1].fill_between(df['time'], residuals, where=anomalies_arima, \n",
    "                     color='red', alpha=0.3, label='–ê–Ω–æ–º–∞–ª—å–Ω—ã–µ –æ—Å—Ç–∞—Ç–∫–∏')\n",
    "axes[1].set_xlabel('–í—Ä–µ–º—è')\n",
    "axes[1].set_ylabel('–û—Å—Ç–∞—Ç–∫–∏')\n",
    "axes[1].set_title('–û—Å—Ç–∞—Ç–∫–∏ ARIMA –º–æ–¥–µ–ª–∏')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "# Z-scores –æ—Å—Ç–∞—Ç–∫–æ–≤\n",
    "axes[2].plot(df['time'], residuals_zscore, label='Z-score –æ—Å—Ç–∞—Ç–∫–æ–≤', alpha=0.7, color='purple')\n",
    "axes[2].axhline(y=threshold_residuals, color='red', linestyle='--', label=f'–ü–æ—Ä–æ–≥ ({threshold_residuals})')\n",
    "axes[2].fill_between(df['time'], 0, residuals_zscore, where=anomalies_arima, \n",
    "                     color='red', alpha=0.3, label='–ê–Ω–æ–º–∞–ª—å–Ω–∞—è –∑–æ–Ω–∞')\n",
    "axes[2].set_xlabel('–í—Ä–µ–º—è')\n",
    "axes[2].set_ylabel('Z-score')\n",
    "axes[2].set_title('Z-scores –æ—Å—Ç–∞—Ç–∫–æ–≤')\n",
    "axes[2].legend()\n",
    "axes[2].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# –ú–µ—Ç—Ä–∏–∫–∏\n",
    "y_pred_arima = anomalies_arima.astype(int)\n",
    "print(\"\\n–ú–µ—Ç—Ä–∏–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞ –º–µ—Ç–æ–¥–∞ ARIMA –æ—Å—Ç–∞—Ç–∫–æ–≤:\")\n",
    "print(f\"Precision: {precision_score(y_true, y_pred_arima):.3f}\")\n",
    "print(f\"Recall: {recall_score(y_true, y_pred_arima):.3f}\")\n",
    "print(f\"F1-Score: {f1_score(y_true, y_pred_arima):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.5 –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –≤—Å–µ—Ö –º–µ—Ç–æ–¥–æ–≤"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# –°–≤–æ–¥–Ω–∞—è —Ç–∞–±–ª–∏—Ü–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤\n",
    "results = pd.DataFrame({\n",
    "    '–ú–µ—Ç–æ–¥': ['Z-score', 'IQR', 'Moving Average', 'Isolation Forest', 'LOF', 'One-Class SVM', 'ARIMA Residuals'],\n",
    "    'Precision': [\n",
    "        precision_score(y_true, y_pred),\n",
    "        precision_score(y_true, y_pred_iqr),\n",
    "        precision_score(y_true, y_pred_ma),\n",
    "        precision_score(y_true, y_pred_if),\n",
    "        precision_score(y_true, y_pred_lof),\n",
    "        precision_score(y_true, y_pred_svm),\n",
    "        precision_score(y_true, y_pred_arima)\n",
    "    ],\n",
    "    'Recall': [\n",
    "        recall_score(y_true, y_pred),\n",
    "        recall_score(y_true, y_pred_iqr),\n",
    "        recall_score(y_true, y_pred_ma),\n",
    "        recall_score(y_true, y_pred_if),\n",
    "        recall_score(y_true, y_pred_lof),\n",
    "        recall_score(y_true, y_pred_svm),\n",
    "        recall_score(y_true, y_pred_arima)\n",
    "    ],\n",
    "    'F1-Score': [\n",
    "        f1_score(y_true, y_pred),\n",
    "        f1_score(y_true, y_pred_iqr),\n",
    "        f1_score(y_true, y_pred_ma),\n",
    "        f1_score(y_true, y_pred_if),\n",
    "        f1_score(y_true, y_pred_lof),\n",
    "        f1_score(y_true, y_pred_svm),\n",
    "        f1_score(y_true, y_pred_arima)\n",
    "    ]\n",
    "})\n",
    "\n",
    "results = results.round(3)\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"–°–†–ê–í–ù–ï–ù–ò–ï –í–°–ï–• –ú–ï–¢–û–î–û–í –û–ë–ù–ê–†–£–ñ–ï–ù–ò–Ø –ê–ù–û–ú–ê–õ–ò–ô\")\n",
    "print(\"=\"*70)\n",
    "print(results.to_string(index=False))\n",
    "print(\"=\"*70)\n",
    "\n",
    "# –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "metrics = ['Precision', 'Recall', 'F1-Score']\n",
    "for idx, metric in enumerate(metrics):\n",
    "    axes[idx].barh(results['–ú–µ—Ç–æ–¥'], results[metric], color='skyblue', edgecolor='black')\n",
    "    axes[idx].set_xlabel(metric)\n",
    "    axes[idx].set_title(f'–°—Ä–∞–≤–Ω–µ–Ω–∏–µ –º–µ—Ç–æ–¥–æ–≤ –ø–æ {metric}')\n",
    "    axes[idx].set_xlim(0, 1)\n",
    "    axes[idx].grid(axis='x', alpha=0.3)\n",
    "    \n",
    "    # –î–æ–±–∞–≤–ª–µ–Ω–∏–µ –∑–Ω–∞—á–µ–Ω–∏–π –Ω–∞ –≥—Ä–∞—Ñ–∏–∫–µ\n",
    "    for i, v in enumerate(results[metric]):\n",
    "        axes[idx].text(v + 0.02, i, f'{v:.3f}', va='center')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ª—É—á—à–µ–≥–æ –º–µ—Ç–æ–¥–∞\n",
    "best_method = results.loc[results['F1-Score'].idxmax()]\n",
    "print(f\"\\nüèÜ –õ—É—á—à–∏–π –º–µ—Ç–æ–¥ –ø–æ F1-Score: {best_method['–ú–µ—Ç–æ–¥']} (F1={best_method['F1-Score']:.3f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. –ü—Ä–æ–¥–≤–∏–Ω—É—Ç—ã–µ —Ç–µ—Ö–Ω–∏–∫–∏\n",
    "\n",
    "### 3.1 Autoencoder –¥–ª—è –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏—è –∞–Ω–æ–º–∞–ª–∏–π"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense\n",
    "\n",
    "# –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö\n",
    "X_train = X_scaled[df['is_anomaly'] == 0]  # –æ–±—É—á–∞–µ–º —Ç–æ–ª—å–∫–æ –Ω–∞ –Ω–æ—Ä–º–∞–ª—å–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö\n",
    "\n",
    "# –ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ Autoencoder\n",
    "input_dim = X_scaled.shape[1]\n",
    "encoding_dim = 4  # —Ä–∞–∑–º–µ—Ä —Å–∂–∞—Ç–æ–≥–æ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏—è\n",
    "\n",
    "# Encoder\n",
    "input_layer = Input(shape=(input_dim,))\n",
    "encoded = Dense(8, activation='relu')(input_layer)\n",
    "encoded = Dense(encoding_dim, activation='relu')(encoded)\n",
    "\n",
    "# Decoder\n",
    "decoded = Dense(8, activation='relu')(encoded)\n",
    "decoded = Dense(input_dim, activation='linear')(decoded)\n",
    "\n",
    "# Autoencoder –º–æ–¥–µ–ª—å\n",
    "autoencoder = Model(input_layer, decoded)\n",
    "autoencoder.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# –û–±—É—á–µ–Ω–∏–µ\n",
    "history_ae = autoencoder.fit(\n",
    "    X_train, X_train,\n",
    "    epochs=50,\n",
    "    batch_size=32,\n",
    "    validation_split=0.2,\n",
    "    verbose=0\n",
    ")\n",
    "\n",
    "# –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –∏ –≤—ã—á–∏—Å–ª–µ–Ω–∏–µ –æ—à–∏–±–∫–∏ —Ä–µ–∫–æ–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏\n",
    "X_pred = autoencoder.predict(X_scaled)\n",
    "reconstruction_error = np.mean(np.abs(X_scaled - X_pred), axis=1)\n",
    "\n",
    "# –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ—Ä–æ–≥–∞ (–Ω–∞–ø—Ä–∏–º–µ—Ä, 95-–π –ø–µ—Ä—Ü–µ–Ω—Ç–∏–ª—å)\n",
    "threshold_ae = np.percentile(reconstruction_error, 95)\n",
    "anomalies_ae = reconstruction_error > threshold_ae\n",
    "\n",
    "# –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è\n",
    "fig, axes = plt.subplots(2, 1, figsize=(16, 10))\n",
    "\n",
    "# –ì—Ä–∞—Ñ–∏–∫ –≤—Ä–µ–º–µ–Ω–Ω–æ–≥–æ —Ä—è–¥–∞\n",
    "axes[0].plot(df['time'], df['value'], label='–í—Ä–µ–º–µ–Ω–Ω–æ–π —Ä—è–¥', alpha=0.7)\n",
    "detected_ae = df[anomalies_ae]\n",
    "axes[0].scatter(detected_ae['time'], detected_ae['value'], \n",
    "                color='red', s=100, label='–û–±–Ω–∞—Ä—É–∂–µ–Ω–Ω—ã–µ –∞–Ω–æ–º–∞–ª–∏–∏ (Autoencoder)', zorder=5)\n",
    "axes[0].scatter(true_anomalies['time'], true_anomalies['value'], \n",
    "                color='orange', s=50, marker='x', label='–ò—Å—Ç–∏–Ω–Ω—ã–µ –∞–Ω–æ–º–∞–ª–∏–∏', zorder=4)\n",
    "axes[0].set_xlabel('–í—Ä–µ–º—è')\n",
    "axes[0].set_ylabel('–ó–Ω–∞—á–µ–Ω–∏–µ')\n",
    "axes[0].set_title('–û–±–Ω–∞—Ä—É–∂–µ–Ω–∏–µ –∞–Ω–æ–º–∞–ª–∏–π —Å –ø–æ–º–æ—â—å—é Autoencoder')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# –ì—Ä–∞—Ñ–∏–∫ –æ—à–∏–±–∫–∏ —Ä–µ–∫–æ–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏\n",
    "axes[1].plot(df['time'], reconstruction_error, label='–û—à–∏–±–∫–∞ —Ä–µ–∫–æ–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏', alpha=0.7, color='blue')\n",
    "axes[1].axhline(y=threshold_ae, color='red', linestyle='--', label=f'–ü–æ—Ä–æ–≥ ({threshold_ae:.3f})')\n",
    "axes[1].fill_between(df['time'], 0, reconstruction_error, where=anomalies_ae, \n",
    "                     color='red', alpha=0.3, label='–ê–Ω–æ–º–∞–ª—å–Ω–∞—è –∑–æ–Ω–∞')\n",
    "axes[1].set_xlabel('–í—Ä–µ–º—è')\n",
    "axes[1].set_ylabel('Reconstruction Error')\n",
    "axes[1].set_title('–û—à–∏–±–∫–∞ —Ä–µ–∫–æ–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏ Autoencoder')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# –ú–µ—Ç—Ä–∏–∫–∏\n",
    "y_pred_ae = anomalies_ae.astype(int)\n",
    "print(\"\\n–ú–µ—Ç—Ä–∏–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞ Autoencoder:\")\n",
    "print(f\"Precision: {precision_score(y_true, y_pred_ae):.3f}\")\n",
    "print(f\"Recall: {recall_score(y_true, y_pred_ae):.3f}\")\n",
    "print(f\"F1-Score: {f1_score(y_true, y_pred_ae):.3f}\")\n",
    "\n",
    "# –ì—Ä–∞—Ñ–∏–∫ –æ–±—É—á–µ–Ω–∏—è\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(history_ae.history['loss'], label='Training Loss')\n",
    "plt.plot(history_ae.history['val_loss'], label='Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('–û–±—É—á–µ–Ω–∏–µ Autoencoder')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 –ê–Ω—Å–∞–º–±–ª—å –º–µ—Ç–æ–¥–æ–≤"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# –°–æ–∑–¥–∞–Ω–∏–µ –∞–Ω—Å–∞–º–±–ª—è –∏–∑ –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö –º–µ—Ç–æ–¥–æ–≤\n",
    "# –ò—Å–ø–æ–ª—å–∑—É–µ–º –≥–æ–ª–æ—Å–æ–≤–∞–Ω–∏–µ (voting)\n",
    "\n",
    "# –°–æ–±–∏—Ä–∞–µ–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –≤—Å–µ—Ö –º–µ—Ç–æ–¥–æ–≤\n",
    "ensemble_predictions = np.column_stack([\n",
    "    y_pred,\n",
    "    y_pred_iqr,\n",
    "    y_pred_ma,\n",
    "    y_pred_if,\n",
    "    y_pred_lof,\n",
    "    y_pred_svm,\n",
    "    y_pred_arima\n",
    "])\n",
    "\n",
    "# –ü—Ä–æ—Å—Ç–æ–µ –≥–æ–ª–æ—Å–æ–≤–∞–Ω–∏–µ: —Å—á–∏—Ç–∞–µ–º –∞–Ω–æ–º–∞–ª–∏–µ–π, –µ—Å–ª–∏ –±–æ–ª—å—à–∏–Ω—Å—Ç–≤–æ –º–µ—Ç–æ–¥–æ–≤ —Å—á–∏—Ç–∞—é—Ç –∞–Ω–æ–º–∞–ª–∏–µ–π\n",
    "threshold_voting = 3  # –º–∏–Ω–∏–º—É–º 3 –∏–∑ 7 –º–µ—Ç–æ–¥–æ–≤ –¥–æ–ª–∂–Ω—ã –æ–±–Ω–∞—Ä—É–∂–∏—Ç—å –∞–Ω–æ–º–∞–ª–∏—é\n",
    "y_pred_ensemble = (ensemble_predictions.sum(axis=1) >= threshold_voting).astype(int)\n",
    "\n",
    "# –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è\n",
    "plt.figure(figsize=(16, 6))\n",
    "plt.plot(df['time'], df['value'], label='–í—Ä–µ–º–µ–Ω–Ω–æ–π —Ä—è–¥', alpha=0.7)\n",
    "detected_ensemble = df[y_pred_ensemble == 1]\n",
    "plt.scatter(detected_ensemble['time'], detected_ensemble['value'], \n",
    "            color='red', s=100, label=f'–û–±–Ω–∞—Ä—É–∂–µ–Ω–Ω—ã–µ –∞–Ω–æ–º–∞–ª–∏–∏ (–ê–Ω—Å–∞–º–±–ª—å, –ø–æ—Ä–æ–≥={threshold_voting})', zorder=5)\n",
    "plt.scatter(true_anomalies['time'], true_anomalies['value'], \n",
    "            color='orange', s=50, marker='x', label='–ò—Å—Ç–∏–Ω–Ω—ã–µ –∞–Ω–æ–º–∞–ª–∏–∏', zorder=4)\n",
    "plt.xlabel('–í—Ä–µ–º—è')\n",
    "plt.ylabel('–ó–Ω–∞—á–µ–Ω–∏–µ')\n",
    "plt.title('–û–±–Ω–∞—Ä—É–∂–µ–Ω–∏–µ –∞–Ω–æ–º–∞–ª–∏–π —Å –ø–æ–º–æ—â—å—é –∞–Ω—Å–∞–º–±–ª—è –º–µ—Ç–æ–¥–æ–≤')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# –ú–µ—Ç—Ä–∏–∫–∏\n",
    "print(\"\\n–ú–µ—Ç—Ä–∏–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞ –ê–Ω—Å–∞–º–±–ª—è:\")\n",
    "print(f\"Precision: {precision_score(y_true, y_pred_ensemble):.3f}\")\n",
    "print(f\"Recall: {recall_score(y_true, y_pred_ensemble):.3f}\")\n",
    "print(f\"F1-Score: {f1_score(y_true, y_pred_ensemble):.3f}\")\n",
    "\n",
    "# –¢–µ–ø–ª–æ–≤–∞—è –∫–∞—Ä—Ç–∞ –≥–æ–ª–æ—Å–æ–≤ –º–µ—Ç–æ–¥–æ–≤\n",
    "plt.figure(figsize=(16, 8))\n",
    "method_names = ['Z-score', 'IQR', 'Moving Avg', 'Iso Forest', 'LOF', 'One-Class SVM', 'ARIMA']\n",
    "sns.heatmap(ensemble_predictions.T, \n",
    "            cmap='RdYlGn_r', \n",
    "            yticklabels=method_names,\n",
    "            cbar_kws={'label': '–ê–Ω–æ–º–∞–ª–∏—è (1) / –ù–æ—Ä–º–∞ (0)'},\n",
    "            vmin=0, vmax=1)\n",
    "plt.xlabel('–í—Ä–µ–º–µ–Ω–Ω—ã–µ —Ç–æ—á–∫–∏')\n",
    "plt.ylabel('–ú–µ—Ç–æ–¥—ã')\n",
    "plt.title('–ì–æ–ª–æ—Å–æ–≤–∞–Ω–∏–µ –º–µ—Ç–æ–¥–æ–≤ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏—è –∞–Ω–æ–º–∞–ª–∏–π')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. –ü—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏\n",
    "\n",
    "### 4.1 –í—ã–±–æ—Ä –º–µ—Ç–æ–¥–∞ –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç –∑–∞–¥–∞—á–∏\n",
    "\n",
    "**–°—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∏–µ –º–µ—Ç–æ–¥—ã (Z-score, IQR, Moving Average):**\n",
    "- ‚úÖ –ü—Ä–æ—Å—Ç–æ—Ç–∞ –∏ —Å–∫–æ—Ä–æ—Å—Ç—å\n",
    "- ‚úÖ –ò–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∏—Ä—É–µ–º–æ—Å—Ç—å\n",
    "- ‚úÖ –•–æ—Ä–æ—à–æ —Ä–∞–±–æ—Ç–∞—é—Ç –Ω–∞ –ø—Ä–æ—Å—Ç—ã—Ö –¥–∞–Ω–Ω—ã—Ö\n",
    "- ‚ùå –ß—É–≤—Å—Ç–≤–∏—Ç–µ–ª—å–Ω—ã –∫ –≤—ã–±—Ä–æ—Å–∞–º\n",
    "- ‚ùå –ü—Ä–µ–¥–ø–æ–ª–∞–≥–∞—é—Ç –Ω–æ—Ä–º–∞–ª—å–Ω–æ–µ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ\n",
    "- **–ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ:** –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –ø—Ä–æ—Å—Ç—ã—Ö –º–µ—Ç—Ä–∏–∫, –±—ã—Å—Ç—Ä–∞—è –ø–µ—Ä–≤–∏—á–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞\n",
    "\n",
    "**Isolation Forest:**\n",
    "- ‚úÖ –≠—Ñ—Ñ–µ–∫—Ç–∏–≤–µ–Ω –¥–ª—è –º–Ω–æ–≥–æ–º–µ—Ä–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö\n",
    "- ‚úÖ –ù–µ —Ç—Ä–µ–±—É–µ—Ç –Ω–æ—Ä–º–∞–ª—å–Ω–æ—Å—Ç–∏ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è\n",
    "- ‚úÖ –ë—ã—Å—Ç—Ä–æ–µ –æ–±—É—á–µ–Ω–∏–µ\n",
    "- ‚ùå –ú–æ–∂–µ—Ç –¥–∞–≤–∞—Ç—å –ª–æ–∂–Ω—ã–µ —Å—Ä–∞–±–∞—Ç—ã–≤–∞–Ω–∏—è\n",
    "- **–ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ:** –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏–µ –∞–Ω–æ–º–∞–ª–∏–π –≤ –º–Ω–æ–≥–æ–º–µ—Ä–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö, –∫–æ–≥–¥–∞ —Å–∫–æ—Ä–æ—Å—Ç—å –≤–∞–∂–Ω–∞\n",
    "\n",
    "**LOF (Local Outlier Factor):**\n",
    "- ‚úÖ –£—á–∏—Ç—ã–≤–∞–µ—Ç –ª–æ–∫–∞–ª—å–Ω—É—é –ø–ª–æ—Ç–Ω–æ—Å—Ç—å\n",
    "- ‚úÖ –•–æ—Ä–æ—à–æ –Ω–∞—Ö–æ–¥–∏—Ç –ª–æ–∫–∞–ª—å–Ω—ã–µ –∞–Ω–æ–º–∞–ª–∏–∏\n",
    "- ‚ùå –ß—É–≤—Å—Ç–≤–∏—Ç–µ–ª–µ–Ω –∫ –≤—ã–±–æ—Ä—É k (—á–∏—Å–ª–∞ —Å–æ—Å–µ–¥–µ–π)\n",
    "- ‚ùå –ú–µ–¥–ª–µ–Ω–Ω–µ–µ –Ω–∞ –±–æ–ª—å—à–∏—Ö –¥–∞–Ω–Ω—ã—Ö\n",
    "- **–ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ:** –∫–æ–≥–¥–∞ –∞–Ω–æ–º–∞–ª–∏–∏ –∏–º–µ—é—Ç –ª–æ–∫–∞–ª—å–Ω—ã–π —Ö–∞—Ä–∞–∫—Ç–µ—Ä\n",
    "\n",
    "**One-Class SVM:**\n",
    "- ‚úÖ –†–∞–±–æ—Ç–∞–µ—Ç —Å –≤—ã—Å–æ–∫–æ—Ä–∞–∑–º–µ—Ä–Ω—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏\n",
    "- ‚úÖ –ì–∏–±–∫–æ—Å—Ç—å —á–µ—Ä–µ–∑ –≤—ã–±–æ—Ä —è–¥—Ä–∞\n",
    "- ‚ùå –¢—Ä–µ–±—É–µ—Ç –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤\n",
    "- ‚ùå –ú–µ–¥–ª–µ–Ω–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ –Ω–∞ –±–æ–ª—å—à–∏—Ö –¥–∞–Ω–Ω—ã—Ö\n",
    "- **–ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ:** –∫–æ–≥–¥–∞ –µ—Å—Ç—å —á–µ—Ç–∫–∞—è –≥—Ä–∞–Ω–∏—Ü–∞ –º–µ–∂–¥—É –Ω–æ—Ä–º–∞–ª—å–Ω—ã–º–∏ –∏ –∞–Ω–æ–º–∞–ª—å–Ω—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏\n",
    "\n",
    "**ARIMA Residuals:**\n",
    "- ‚úÖ –£—á–∏—Ç—ã–≤–∞–µ—Ç –≤—Ä–µ–º–µ–Ω–Ω—É—é —Å—Ç—Ä—É–∫—Ç—É—Ä—É\n",
    "- ‚úÖ –•–æ—Ä–æ—à–æ –¥–ª—è –ø—Ä–æ–≥–Ω–æ–∑–∏—Ä—É–µ–º—ã—Ö —Ä—è–¥–æ–≤\n",
    "- ‚ùå –¢—Ä–µ–±—É–µ—Ç —Å—Ç–∞—Ü–∏–æ–Ω–∞—Ä–Ω–æ—Å—Ç–∏\n",
    "- ‚ùå –°–ª–æ–∂–Ω–æ—Å—Ç—å –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –º–æ–¥–µ–ª–∏\n",
    "- **–ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ:** –≤—Ä–µ–º–µ–Ω–Ω—ã–µ —Ä—è–¥—ã —Å —Ç—Ä–µ–Ω–¥–æ–º –∏ —Å–µ–∑–æ–Ω–Ω–æ—Å—Ç—å—é\n",
    "\n",
    "**Autoencoder:**\n",
    "- ‚úÖ –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤\n",
    "- ‚úÖ –≠—Ñ—Ñ–µ–∫—Ç–∏–≤–µ–Ω –¥–ª—è —Å–ª–æ–∂–Ω—ã—Ö –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤\n",
    "- ‚ùå –¢—Ä–µ–±—É–µ—Ç –±–æ–ª—å—à–µ –¥–∞–Ω–Ω—ã—Ö\n",
    "- ‚ùå –ú–µ–Ω–µ–µ –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∏—Ä—É–µ–º\n",
    "- **–ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ:** —Å–ª–æ–∂–Ω—ã–µ –º–Ω–æ–≥–æ–º–µ—Ä–Ω—ã–µ –≤—Ä–µ–º–µ–Ω–Ω—ã–µ —Ä—è–¥—ã, –∫–æ–≥–¥–∞ –º–Ω–æ–≥–æ –Ω–æ—Ä–º–∞–ª—å–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö\n",
    "\n",
    "**–ê–Ω—Å–∞–º–±–ª—å:**\n",
    "- ‚úÖ –ë–æ–ª–µ–µ –Ω–∞–¥–µ–∂–µ–Ω\n",
    "- ‚úÖ –£–º–µ–Ω—å—à–∞–µ—Ç –ª–æ–∂–Ω—ã–µ —Å—Ä–∞–±–∞—Ç—ã–≤–∞–Ω–∏—è\n",
    "- ‚ùå –ë–æ–ª—å—à–µ –≤—ã—á–∏—Å–ª–µ–Ω–∏–π\n",
    "- **–ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ:** –∫—Ä–∏—Ç–∏—á–Ω—ã–µ —Å–∏—Å—Ç–µ–º—ã, –≥–¥–µ –≤–∞–∂–Ω–∞ –Ω–∞–¥–µ–∂–Ω–æ—Å—Ç—å\n",
    "\n",
    "### 4.2 –û–±—Ä–∞–±–æ—Ç–∫–∞ –¥–∏—Å–±–∞–ª–∞–Ω—Å–∞ –∫–ª–∞—Å—Å–æ–≤\n",
    "\n",
    "–ê–Ω–æ–º–∞–ª–∏–∏ –æ–±—ã—á–Ω–æ —Å–æ—Å—Ç–∞–≤–ª—è—é—Ç –º–∞–ª—É—é –¥–æ–ª—é –¥–∞–Ω–Ω—ã—Ö (1-5%), —á—Ç–æ —Å–æ–∑–¥–∞–µ—Ç –ø—Ä–æ–±–ª–µ–º—É –¥–∏—Å–±–∞–ª–∞–Ω—Å–∞:\n",
    "\n",
    "1. **–ü—Ä–∞–≤–∏–ª—å–Ω—ã–π –≤—ã–±–æ—Ä –º–µ—Ç—Ä–∏–∫:** –Ω–µ –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ accuracy, –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ Precision, Recall, F1-Score, ROC-AUC\n",
    "2. **–ù–∞—Å—Ç—Ä–æ–π–∫–∞ contamination:** –≤ –º–µ—Ç–æ–¥–∞—Ö ML —É–∫–∞–∑—ã–≤–∞–π—Ç–µ –æ–∂–∏–¥–∞–µ–º—É—é –¥–æ–ª—é –∞–Ω–æ–º–∞–ª–∏–π\n",
    "3. **Threshold tuning:** –ø–æ–¥–±–∏—Ä–∞–π—Ç–µ –ø–æ—Ä–æ–≥ –ø–æ–¥ –∑–∞–¥–∞—á—É (–±–æ–ª—å—à–µ Precision –∏–ª–∏ Recall?)\n",
    "\n",
    "### 4.3 –ü—Ä–æ–∏–∑–≤–æ–¥—Å—Ç–≤–µ–Ω–Ω—ã–µ —Å–∏—Å—Ç–µ–º—ã (Production)\n",
    "\n",
    "**–ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –∫–∞—á–µ—Å—Ç–≤–∞:**\n",
    "- –†–µ–≥—É–ª—è—Ä–Ω–æ –ø—Ä–æ–≤–µ—Ä—è–π—Ç–µ False Positive Rate\n",
    "- –°–æ–±–∏—Ä–∞–π—Ç–µ –æ–±—Ä–∞—Ç–Ω—É—é —Å–≤—è–∑—å –æ—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π\n",
    "- –ü–µ—Ä–µ–æ–±—É—á–∞–π—Ç–µ –º–æ–¥–µ–ª–∏ –Ω–∞ –Ω–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö\n",
    "\n",
    "**–ú–∞—Å—à—Ç–∞–±–∏—Ä—É–µ–º–æ—Å—Ç—å:**\n",
    "- –î–ª—è real-time: –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ –ø—Ä–æ—Å—Ç—ã–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∏–µ –º–µ—Ç–æ–¥—ã –∏–ª–∏ Isolation Forest\n",
    "- –î–ª—è batch processing: –º–æ–∂–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –±–æ–ª–µ–µ —Å–ª–æ–∂–Ω—ã–µ –º–µ—Ç–æ–¥—ã\n",
    "\n",
    "**–ò–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∏—Ä—É–µ–º–æ—Å—Ç—å:**\n",
    "- –°–æ—Ö—Ä–∞–Ω—è–π—Ç–µ –Ω–µ —Ç–æ–ª—å–∫–æ –º–µ—Ç–∫—É –∞–Ω–æ–º–∞–ª–∏–∏, –Ω–æ –∏ score/confidence\n",
    "- –õ–æ–≥–∏—Ä—É–π—Ç–µ –ø—Ä–∏—á–∏–Ω—É –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏—è (–∫–∞–∫–æ–π –ø—Ä–∏–∑–Ω–∞–∫ –∞–Ω–æ–º–∞–ª–µ–Ω)\n",
    "- –í–∏–∑—É–∞–ª–∏–∑–∏—Ä—É–π—Ç–µ –∞–Ω–æ–º–∞–ª–∏–∏ –¥–ª—è –∞–Ω–∞–ª–∏—Ç–∏–∫–æ–≤"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. –ó–∞–¥–∞–Ω–∏—è –¥–ª—è —Å–∞–º–æ—Å—Ç–æ—è—Ç–µ–ª—å–Ω–æ–π —Ä–∞–±–æ—Ç—ã\n",
    "\n",
    "### –ó–∞–¥–∞–Ω–∏–µ 1: –ë–∞–∑–æ–≤–æ–µ (–æ–±—è–∑–∞—Ç–µ–ª—å–Ω–æ–µ)\n",
    "\n",
    "–ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ —Ä–µ–∞–ª—å–Ω—ã–π –¥–∞—Ç–∞—Å–µ—Ç (–Ω–∞–ø—Ä–∏–º–µ—Ä, –¥–∞–Ω–Ω—ã–µ –æ –ø–æ—Ç—Ä–µ–±–ª–µ–Ω–∏–∏ —ç–ª–µ–∫—Ç—Ä–æ—ç–Ω–µ—Ä–≥–∏–∏ –∏–ª–∏ —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä—ã) –∏:\n",
    "1. –ü—Ä–∏–º–µ–Ω–∏—Ç–µ –º–∏–Ω–∏–º—É–º 3 —Ä–∞–∑–ª–∏—á–Ω—ã—Ö –º–µ—Ç–æ–¥–∞ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏—è –∞–Ω–æ–º–∞–ª–∏–π\n",
    "2. –°—Ä–∞–≤–Ω–∏—Ç–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã\n",
    "3. –ü—Ä–æ–≤–µ–¥–∏—Ç–µ –≤–∏–∑—É–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–Ω—ã—Ö –∞–Ω–æ–º–∞–ª–∏–π\n",
    "4. –í—ã–±–µ—Ä–∏—Ç–µ –Ω–∞–∏–±–æ–ª–µ–µ –ø–æ–¥—Ö–æ–¥—è—â–∏–π –º–µ—Ç–æ–¥ –∏ –æ–±–æ—Å–Ω—É–π—Ç–µ –≤—ã–±–æ—Ä\n",
    "\n",
    "**–ö—Ä–∏—Ç–µ—Ä–∏–∏ –æ—Ü–µ–Ω–∫–∏:**\n",
    "- –ö–æ—Ä—Ä–µ–∫—Ç–Ω–∞—è —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—è –º–µ—Ç–æ–¥–æ–≤\n",
    "- –ö–∞—á–µ—Å—Ç–≤–µ–Ω–Ω–∞—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è\n",
    "- –ê–Ω–∞–ª–∏–∑ –∏ –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# –ú–µ—Å—Ç–æ –¥–ª—è —Ä–µ—à–µ–Ω–∏—è –∑–∞–¥–∞–Ω–∏—è 1\n",
    "# TODO: –í–∞—à –∫–æ–¥ –∑–¥–µ—Å—å"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### –ó–∞–¥–∞–Ω–∏–µ 2: –ü—Ä–æ–¥–≤–∏–Ω—É—Ç–æ–µ\n",
    "\n",
    "–†–µ–∞–ª–∏–∑—É–π—Ç–µ —Å–∏—Å—Ç–µ–º—É –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏—è –∞–Ω–æ–º–∞–ª–∏–π –≤ —Ä–µ–∂–∏–º–µ —Ä–µ–∞–ª—å–Ω–æ–≥–æ –≤—Ä–µ–º–µ–Ω–∏:\n",
    "1. –°–æ–∑–¥–∞–π—Ç–µ —Ñ—É–Ω–∫—Ü–∏—é, –∫–æ—Ç–æ—Ä–∞—è –ø—Ä–∏–Ω–∏–º–∞–µ—Ç –Ω–æ–≤—É—é —Ç–æ—á–∫—É –¥–∞–Ω–Ω—ã—Ö –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ –æ–Ω–∞ –∞–Ω–æ–º–∞–ª–∏–µ–π\n",
    "2. –†–µ–∞–ª–∏–∑—É–π—Ç–µ –º–µ—Ö–∞–Ω–∏–∑–º –∞–¥–∞–ø—Ç–∏–≤–Ω–æ–≥–æ –ø–æ—Ä–æ–≥–∞ (threshold adapts over time)\n",
    "3. –î–æ–±–∞–≤—å—Ç–µ –ª–æ–≥–∏–∫—É –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ä–∞–∑–ª–∏—á–Ω—ã—Ö —Ç–∏–ø–æ–≤ –∞–Ω–æ–º–∞–ª–∏–π:\n",
    "   - –¢–æ—á–µ—á–Ω—ã–µ –∞–Ω–æ–º–∞–ª–∏–∏\n",
    "   - –ö–æ–Ω—Ç–µ–∫—Å—Ç—É–∞–ª—å–Ω—ã–µ –∞–Ω–æ–º–∞–ª–∏–∏\n",
    "   - –ö–æ–ª–ª–µ–∫—Ç–∏–≤–Ω—ã–µ –∞–Ω–æ–º–∞–ª–∏–∏ (–Ω–µ—Å–∫–æ–ª—å–∫–æ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω—ã—Ö —Ç–æ—á–µ–∫)\n",
    "4. –°–æ–∑–¥–∞–π—Ç–µ —Å–∏—Å—Ç–µ–º—É –∞–ª–µ—Ä—Ç–æ–≤ —Å —Ä–∞–∑–ª–∏—á–Ω—ã–º–∏ —É—Ä–æ–≤–Ω—è–º–∏ –∫—Ä–∏—Ç–∏—á–Ω–æ—Å—Ç–∏\n",
    "5. –í–∏–∑—É–∞–ª–∏–∑–∏—Ä—É–π—Ç–µ —Ä–∞–±–æ—Ç—É —Å–∏—Å—Ç–µ–º—ã –≤ –¥–∏–Ω–∞–º–∏–∫–µ\n",
    "\n",
    "**–î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ:** —Ä–µ–∞–ª–∏–∑—É–π—Ç–µ –º–µ—Ö–∞–Ω–∏–∑–º –æ–±—Ä–∞—Ç–Ω–æ–π —Å–≤—è–∑–∏ –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è –º–æ–¥–µ–ª–∏"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# –ú–µ—Å—Ç–æ –¥–ª—è —Ä–µ—à–µ–Ω–∏—è –∑–∞–¥–∞–Ω–∏—è 2\n",
    "# TODO: –í–∞—à –∫–æ–¥ –∑–¥–µ—Å—å"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### –ó–∞–¥–∞–Ω–∏–µ 3: –ò—Å—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å—Å–∫–æ–µ\n",
    "\n",
    "–ü—Ä–æ–≤–µ–¥–∏—Ç–µ –∫–æ–º–ø–ª–µ–∫—Å–Ω–æ–µ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏—è –∞–Ω–æ–º–∞–ª–∏–π:\n",
    "1. –ù–∞–π–¥–∏—Ç–µ –∏–ª–∏ —Å–æ–∑–¥–∞–π—Ç–µ –¥–∞—Ç–∞—Å–µ—Ç —Å –∏–∑–≤–µ—Å—Ç–Ω—ã–º–∏ –∞–Ω–æ–º–∞–ª–∏—è–º–∏ (–º–æ–∂–µ—Ç–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å Yahoo S5 –∏–ª–∏ NAB datasets)\n",
    "2. –†–µ–∞–ª–∏–∑—É–π—Ç–µ –º–∏–Ω–∏–º—É–º 7 —Ä–∞–∑–ª–∏—á–Ω—ã—Ö –º–µ—Ç–æ–¥–æ–≤ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏—è –∞–Ω–æ–º–∞–ª–∏–π\n",
    "3. –ü—Ä–æ–≤–µ–¥–∏—Ç–µ grid search –¥–ª—è –ø–æ–¥–±–æ—Ä–∞ –æ–ø—Ç–∏–º–∞–ª—å–Ω—ã—Ö –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –∫–∞–∂–¥–æ–≥–æ –º–µ—Ç–æ–¥–∞\n",
    "4. –ü–æ—Å—Ç—Ä–æ–π—Ç–µ ROC-–∫—Ä–∏–≤—ã–µ –¥–ª—è –≤—Å–µ—Ö –º–µ—Ç–æ–¥–æ–≤\n",
    "5. –†–µ–∞–ª–∏–∑—É–π—Ç–µ –∏ –æ—Ü–µ–Ω–∏—Ç–µ –Ω–µ—Å–∫–æ–ª—å–∫–æ —Å—Ç—Ä–∞—Ç–µ–≥–∏–π –∞–Ω—Å–∞–º–±–ª–∏—Ä–æ–≤–∞–Ω–∏—è:\n",
    "   - –ì–æ–ª–æ—Å–æ–≤–∞–Ω–∏–µ –±–æ–ª—å—à–∏–Ω—Å—Ç–≤–æ–º\n",
    "   - –í–∑–≤–µ—à–µ–Ω–Ω–æ–µ –≥–æ–ª–æ—Å–æ–≤–∞–Ω–∏–µ\n",
    "   - Stacking\n",
    "6. –°–æ–∑–¥–∞–π—Ç–µ –∏—Ç–æ–≥–æ–≤—ã–π –æ—Ç—á–µ—Ç —Å —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è–º–∏ –ø–æ –≤—ã–±–æ—Ä—É –º–µ—Ç–æ–¥–∞ –≤ —Ä–∞–∑–ª–∏—á–Ω—ã—Ö —Å—Ü–µ–Ω–∞—Ä–∏—è—Ö\n",
    "7. –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π—Ç–µ –≤—ã—á–∏—Å–ª–∏—Ç–µ–ª—å–Ω—É—é —Å–ª–æ–∂–Ω–æ—Å—Ç—å –∫–∞–∂–¥–æ–≥–æ –º–µ—Ç–æ–¥–∞\n",
    "\n",
    "**–ö—Ä–∏—Ç–µ—Ä–∏–∏ –æ—Ü–µ–Ω–∫–∏:**\n",
    "- –ü–æ–ª–Ω–æ—Ç–∞ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è\n",
    "- –ö–∞—á–µ—Å—Ç–≤–æ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–æ–≤\n",
    "- –ì–ª—É–±–∏–Ω–∞ –∞–Ω–∞–ª–∏–∑–∞\n",
    "- –ü—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# –ú–µ—Å—Ç–æ –¥–ª—è —Ä–µ—à–µ–Ω–∏—è –∑–∞–¥–∞–Ω–∏—è 3\n",
    "# TODO: –í–∞—à –∫–æ–¥ –∑–¥–µ—Å—å"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## –ö–æ–Ω—Ç—Ä–æ–ª—å–Ω—ã–µ –≤–æ–ø—Ä–æ—Å—ã\n",
    "\n",
    "1. –û–ø–∏—à–∏—Ç–µ —Ç—Ä–∏ —Ç–∏–ø–∞ –∞–Ω–æ–º–∞–ª–∏–π –≤–æ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ä—è–¥–∞—Ö –∏ –ø—Ä–∏–≤–µ–¥–∏—Ç–µ –ø—Ä–∏–º–µ—Ä—ã.\n",
    "2. –í —á–µ–º —Ä–∞–∑–Ω–∏—Ü–∞ –º–µ–∂–¥—É Z-score –∏ IQR –º–µ—Ç–æ–¥–∞–º–∏? –ö–æ–≥–¥–∞ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –∫–∞–∂–¥—ã–π?\n",
    "3. –ö–∞–∫ —Ä–∞–±–æ—Ç–∞–µ—Ç Isolation Forest? –ü–æ—á–µ–º—É –æ–Ω —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–µ–Ω –¥–ª—è –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏—è –∞–Ω–æ–º–∞–ª–∏–π?\n",
    "4. –û–±—ä—è—Å–Ω–∏—Ç–µ –∫–æ–Ω—Ü–µ–ø—Ü–∏—é Local Outlier Factor (LOF).\n",
    "5. –ü–æ—á–µ–º—É Autoencoder –º–æ–∂–µ—Ç –±—ã—Ç—å —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–µ–Ω –¥–ª—è –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏—è –∞–Ω–æ–º–∞–ª–∏–π?\n",
    "6. –ö–∞–∫ –≤—ã–±—Ä–∞—Ç—å –æ–ø—Ç–∏–º–∞–ª—å–Ω—ã–π –ø–æ—Ä–æ–≥ (threshold) –¥–ª—è –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏—è –∞–Ω–æ–º–∞–ª–∏–π?\n",
    "7. –ü–æ—á–µ–º—É accuracy –Ω–µ –ø–æ–¥—Ö–æ–¥–∏—Ç –¥–ª—è –æ—Ü–µ–Ω–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏—è –∞–Ω–æ–º–∞–ª–∏–π?\n",
    "8. –í —á–µ–º –ø—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–∞ –∞–Ω—Å–∞–º–±–ª–µ–≤–æ–≥–æ –ø–æ–¥—Ö–æ–¥–∞?\n",
    "9. –ö–∞–∫ –∞–¥–∞–ø—Ç–∏—Ä–æ–≤–∞—Ç—å –º–µ—Ç–æ–¥—ã –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏—è –∞–Ω–æ–º–∞–ª–∏–π –¥–ª—è —Ä–∞–±–æ—Ç—ã –≤ —Ä–µ–∂–∏–º–µ —Ä–µ–∞–ª—å–Ω–æ–≥–æ –≤—Ä–µ–º–µ–Ω–∏?\n",
    "10. –ö–∞–∫–∏–µ —Ñ–∞–∫—Ç–æ—Ä—ã –Ω—É–∂–Ω–æ —É—á–∏—Ç—ã–≤–∞—Ç—å –ø—Ä–∏ –≤—ã–±–æ—Ä–µ –º–µ—Ç–æ–¥–∞ –¥–ª—è production —Å–∏—Å—Ç–µ–º—ã?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –º–∞—Ç–µ—Ä–∏–∞–ª—ã\n",
    "\n",
    "**–°—Ç–∞—Ç—å–∏:**\n",
    "- Chandola, V., Banerjee, A., & Kumar, V. (2009). Anomaly detection: A survey. ACM computing surveys (CSUR), 41(3), 1-58.\n",
    "- Liu, F. T., Ting, K. M., & Zhou, Z. H. (2008). Isolation forest. In ICDM '08.\n",
    "- Breunig, M. M., et al. (2000). LOF: identifying density-based local outliers.\n",
    "\n",
    "**–û–Ω–ª–∞–π–Ω —Ä–µ—Å—É—Ä—Å—ã:**\n",
    "- [Scikit-learn: Outlier Detection](https://scikit-learn.org/stable/modules/outlier_detection.html)\n",
    "- [Twitter Anomaly Detection](https://github.com/twitter/AnomalyDetection)\n",
    "- [NAB (Numenta Anomaly Benchmark)](https://github.com/numenta/NAB)\n",
    "\n",
    "**–î–∞—Ç–∞—Å–µ—Ç—ã:**\n",
    "- [Yahoo S5](https://webscope.sandbox.yahoo.com/catalog.php?datatype=s&did=70)\n",
    "- [NAB Dataset](https://github.com/numenta/NAB/tree/master/data)\n",
    "- [UCR Time Series Anomaly Archive](https://www.cs.ucr.edu/~eamonn/time_series_data_2018/)\n",
    "\n",
    "**–ö–Ω–∏–≥–∏:**\n",
    "- Aggarwal, C. C. (2017). Outlier Analysis. Springer.\n",
    "- Goldstein, M., & Uchida, S. (2016). A Comparative Evaluation of Unsupervised Anomaly Detection Algorithms for Multivariate Data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}