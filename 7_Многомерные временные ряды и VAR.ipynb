{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "4bf9ec77",
      "metadata": {
        "id": "4bf9ec77"
      },
      "source": [
        "# Многомерные временные ряды и VAR\n",
        "Полный учебный ноутбук с теорией и практикой."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "347aa324",
      "metadata": {
        "id": "347aa324"
      },
      "source": [
        "## Введение в многомерные временные ряды"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "83440c2d",
      "metadata": {
        "id": "83440c2d"
      },
      "source": [
        "Многомерные временные ряды представляют собой набор нескольких рядов, измеряемых одновременно. Они применяются в экономике, финансах, IoT, метеорологии и других областях, где переменные взаимосвязаны. Такие ряды демонстрируют перекрестные корреляции, общие тренды, коинтеграцию и сложные многомерные паттерны."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "85ab64de",
      "metadata": {
        "id": "85ab64de"
      },
      "source": [
        "## Импорт библиотек"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b964b6dd",
      "metadata": {
        "id": "b964b6dd"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from statsmodels.tsa.api import VAR\n",
        "from statsmodels.tsa.stattools import adfuller, grangercausalitytests\n",
        "from statsmodels.tsa.vector_ar.vecm import coint_johansen\n",
        "from statsmodels.stats.stattools import durbin_watson\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "plt.style.use('seaborn-v0_8-darkgrid')\n",
        "plt.rcParams['figure.figsize']=(15,8)\n",
        "plt.rcParams['font.size']=12\n",
        "np.random.seed(42)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9924cb2c",
      "metadata": {
        "id": "9924cb2c"
      },
      "source": [
        "## Генерация синтетических многомерных временных рядов"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2ec8309f",
      "metadata": {
        "id": "2ec8309f"
      },
      "outputs": [],
      "source": [
        "def generate_multivariate_ts(n_points=200, n_series=3, trend_strength=0.02,\n",
        "                            seasonality_period=50, noise_level=0.5,\n",
        "                            cross_correlation=0.7):\n",
        "    \"\"\"\n",
        "    Генерация многомерного временного ряда с корреляцией между компонентами\n",
        "\n",
        "    Параметры:\n",
        "    n_points: количество точек\n",
        "    n_series: количество временных рядов\n",
        "    trend_strength: сила тренда\n",
        "    seasonality_period: период сезонности\n",
        "    noise_level: уровень шума\n",
        "    cross_correlation: уровень корреляции между рядами\n",
        "    \"\"\"\n",
        "    # Базовые компоненты\n",
        "    time_index = pd.date_range(start='2023-01-01', periods=n_points, freq='D')\n",
        "\n",
        "    # Матрица для хранения всех рядов\n",
        "    all_series = np.zeros((n_points, n_series))\n",
        "\n",
        "    # Общие компоненты (тренд, сезонность)\n",
        "    common_trend = trend_strength * np.arange(n_points)\n",
        "    common_seasonality = 5 * np.sin(2 * np.pi * np.arange(n_points) / seasonality_period)\n",
        "\n",
        "    # Генерация каждого ряда\n",
        "    for i in range(n_series):\n",
        "        # Индивидуальный тренд\n",
        "        individual_trend = 0.01 * (i+1) * np.arange(n_points)\n",
        "\n",
        "        # Индивидуальная сезонность\n",
        "        phase_shift = i * 2 * np.pi / n_series\n",
        "        individual_seasonality = 3 * np.sin(2 * np.pi * np.arange(n_points) /\n",
        "                                           seasonality_period + phase_shift)\n",
        "\n",
        "        # Базовое значение\n",
        "        base_value = 20 * (i+1) + common_trend + common_seasonality + \\\n",
        "                    individual_trend + individual_seasonality\n",
        "\n",
        "        # Добавление автокорреляции\n",
        "        ar_component = np.zeros(n_points)\n",
        "        for t in range(2, n_points):\n",
        "            ar_component[t] = 0.7 * base_value[t-1] - 0.2 * base_value[t-2]\n",
        "\n",
        "        # Перекрестная корреляция с другими рядами\n",
        "        cross_corr_component = np.zeros(n_points)\n",
        "        if i > 0:\n",
        "            for j in range(i):\n",
        "                cross_corr_component += cross_correlation * 0.3 * all_series[:, j]\n",
        "\n",
        "        # Шум\n",
        "        noise = noise_level * (i+1) * np.random.randn(n_points)\n",
        "\n",
        "        # Итоговый ряд\n",
        "        all_series[:, i] = base_value + ar_component + cross_corr_component + noise\n",
        "\n",
        "    # Создание DataFrame\n",
        "    columns = [f'Series_{i+1}' for i in range(n_series)]\n",
        "    df = pd.DataFrame(all_series, index=time_index, columns=columns)\n",
        "\n",
        "    # Добавление описательных статистик\n",
        "    df['timestamp'] = time_index\n",
        "    df.set_index('timestamp', inplace=True)\n",
        "\n",
        "    return df\n",
        "\n",
        "# Генерация данных\n",
        "n_series = 4\n",
        "df = generate_multivariate_ts(n_points=200, n_series=n_series,\n",
        "                             trend_strength=0.01, seasonality_period=30,\n",
        "                             cross_correlation=0.6)\n",
        "\n",
        "# Визуализация многомерного временного ряда\n",
        "fig, axes = plt.subplots(2, 2, figsize=(16, 10))\n",
        "colors = ['blue', 'green', 'red', 'purple']\n",
        "\n",
        "for i, (col, ax) in enumerate(zip(df.columns, axes.flatten())):\n",
        "    ax.plot(df.index, df[col], color=colors[i], linewidth=2)\n",
        "    ax.set_title(f'Временной ряд {col}', fontsize=14)\n",
        "    ax.set_xlabel('Дата')\n",
        "    ax.set_ylabel('Значение')\n",
        "    ax.grid(True, alpha=0.3)\n",
        "\n",
        "    # Добавление статистики на график\n",
        "    stats_text = f'Mean: {df[col].mean():.2f}\\nStd: {df[col].std():.2f}'\n",
        "    ax.text(0.02, 0.95, stats_text, transform=ax.transAxes,\n",
        "            fontsize=10, verticalalignment='top',\n",
        "            bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))\n",
        "\n",
        "plt.suptitle('Многомерный временной ряд (4 компоненты)', fontsize=16)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Корреляционная матрица\n",
        "corr_matrix = df.corr()\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', center=0,\n",
        "            square=True, linewidths=1, cbar_kws={\"shrink\": .8})\n",
        "plt.title('Корреляционная матрица временных рядов', fontsize=16)\n",
        "plt.show()\n",
        "\n",
        "print(\"Основные статистики многомерного ряда:\")\n",
        "print(df.describe())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1a1f3de3",
      "metadata": {
        "id": "1a1f3de3"
      },
      "source": [
        "## Проверка стационарности"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "787c319c",
      "metadata": {
        "id": "787c319c"
      },
      "outputs": [],
      "source": [
        "def check_stationarity(series, significance_level=0.05):\n",
        "    \"\"\"\n",
        "    Проверка стационарности временного ряда с помощью ADF теста\n",
        "    \"\"\"\n",
        "    result = adfuller(series)\n",
        "\n",
        "    print(f'ADF Statistic: {result[0]:.4f}')\n",
        "    print(f'p-value: {result[1]:.4f}')\n",
        "    print('Критические значения:')\n",
        "    for key, value in result[4].items():\n",
        "        print(f'\\t{key}: {value:.4f}')\n",
        "\n",
        "    if result[1] <= significance_level:\n",
        "        print(f\"Ряд стационарен (p-value ≤ {significance_level})\")\n",
        "        return True\n",
        "    else:\n",
        "        print(f\"Ряд нестационарен (p-value > {significance_level})\")\n",
        "        return False\n",
        "\n",
        "# Проверка стационарности каждого ряда\n",
        "print(\"=\" * 60)\n",
        "print(\"Проверка стационарности временных рядов\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "stationarity_results = {}\n",
        "for col in df.columns:\n",
        "    print(f\"\\nАнализ ряда: {col}\")\n",
        "    print(\"-\" * 40)\n",
        "    is_stationary = check_stationarity(df[col])\n",
        "    stationarity_results[col] = is_stationary\n",
        "\n",
        "# Разностное преобразование для нестационарных рядов\n",
        "def make_stationary(df):\n",
        "    \"\"\"\n",
        "    Преобразование рядов к стационарному виду\n",
        "    \"\"\"\n",
        "    df_stationary = df.copy()\n",
        "\n",
        "    for col in df.columns:\n",
        "        if not stationarity_results.get(col, False):\n",
        "            # Первая разность\n",
        "            df_stationary[col] = df[col].diff().dropna()\n",
        "            # Проверка после преобразования\n",
        "            print(f\"\\nПроверка стационарности после дифференцирования {col}:\")\n",
        "            if len(df_stationary[col].dropna()) > 0:\n",
        "                check_stationarity(df_stationary[col].dropna())\n",
        "\n",
        "    return df_stationary.dropna()\n",
        "\n",
        "# Применяем преобразование если нужно\n",
        "if not all(stationarity_results.values()):\n",
        "    print(\"\\n\" + \"=\" * 60)\n",
        "    print(\"Применение разностного преобразования\")\n",
        "    print(\"=\" * 60)\n",
        "    df_stationary = make_stationary(df)\n",
        "else:\n",
        "    df_stationary = df.copy()\n",
        "\n",
        "# Визуализация стационарных рядов\n",
        "fig, axes = plt.subplots(2, 2, figsize=(16, 10))\n",
        "for i, (col, ax) in enumerate(zip(df_stationary.columns, axes.flatten())):\n",
        "    ax.plot(df_stationary.index, df_stationary[col], color=colors[i], linewidth=2)\n",
        "    ax.set_title(f'Стационарный ряд {col}', fontsize=14)\n",
        "    ax.set_xlabel('Дата')\n",
        "    ax.set_ylabel('Значение')\n",
        "    ax.axhline(y=0, color='red', linestyle='--', alpha=0.5)\n",
        "    ax.grid(True, alpha=0.3)\n",
        "\n",
        "plt.suptitle('Стационарные временные ряды', fontsize=16)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Построение VAR модели"
      ],
      "metadata": {
        "id": "HuUbgjRpXZ4f"
      },
      "id": "HuUbgjRpXZ4f"
    },
    {
      "cell_type": "code",
      "source": [
        "def select_var_lag(df, max_lag=15):\n",
        "    \"\"\"\n",
        "    Выбор оптимального лага для VAR модели\n",
        "    \"\"\"\n",
        "    # Разделение на обучающую и тестовую выборки\n",
        "    train_size = int(len(df) * 0.8)\n",
        "    train_data = df.iloc[:train_size]\n",
        "\n",
        "    # Подбор оптимального лага\n",
        "    model = VAR(train_data)\n",
        "\n",
        "    # Используем разные информационные критерии\n",
        "    print(\"Подбор оптимального лага для VAR модели:\")\n",
        "    print(\"-\" * 50)\n",
        "\n",
        "    for criterion in ['aic', 'bic', 'hqic']:\n",
        "        lag_results = model.select_order(maxlags=max_lag)\n",
        "        optimal_lag = getattr(lag_results, criterion)\n",
        "        print(f\"Оптимальный лаг по {criterion.upper()}: {optimal_lag}\")\n",
        "\n",
        "    # Визуализация критериев\n",
        "    lags = range(1, max_lag + 1)\n",
        "    aic_values = []\n",
        "    bic_values = []\n",
        "    hqic_values = []\n",
        "\n",
        "    for lag in lags:\n",
        "        try:\n",
        "            result = model.fit(lag)\n",
        "            aic_values.append(result.aic)\n",
        "            bic_values.append(result.bic)\n",
        "            hqic_values.append(result.hqic)\n",
        "        except:\n",
        "            aic_values.append(np.nan)\n",
        "            bic_values.append(np.nan)\n",
        "            hqic_values.append(np.nan)\n",
        "\n",
        "    # График информационных критериев\n",
        "    plt.figure(figsize=(12, 6))\n",
        "    plt.plot(lags, aic_values, marker='o', label='AIC', linewidth=2)\n",
        "    plt.plot(lags, bic_values, marker='s', label='BIC', linewidth=2)\n",
        "    plt.plot(lags, hqic_values, marker='^', label='HQIC', linewidth=2)\n",
        "    plt.xlabel('Порядок лага (p)')\n",
        "    plt.ylabel('Значение критерия')\n",
        "    plt.title('Информационные критерии для выбора порядка VAR модели', fontsize=16)\n",
        "    plt.legend()\n",
        "    plt.grid(True, alpha=0.3)\n",
        "    plt.show()\n",
        "\n",
        "    # Рекомендуемый лаг (по AIC, но с учетом парсимоничности)\n",
        "    recommended_lag = int(np.nanargmin(aic_values) + 1)\n",
        "    print(f\"\\nРекомендуемый лаг для VAR модели: {recommended_lag}\")\n",
        "\n",
        "    return recommended_lag\n",
        "\n",
        "# Выбор оптимального лага\n",
        "optimal_lag = select_var_lag(df_stationary, max_lag=10)\n",
        "\n",
        "# Разделение данных на обучающую и тестовую выборки\n",
        "train_size = int(len(df_stationary) * 0.8)\n",
        "train_data = df_stationary.iloc[:train_size]\n",
        "test_data = df_stationary.iloc[train_size:]\n",
        "\n",
        "print(f\"\\nРазмеры выборок:\")\n",
        "print(f\"Обучающая выборка: {len(train_data)} наблюдений\")\n",
        "print(f\"Тестовая выборка: {len(test_data)} наблюдений\")\n",
        "\n",
        "# Обучение VAR модели\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"Обучение VAR модели\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "var_model = VAR(train_data)\n",
        "var_result = var_model.fit(optimal_lag)\n",
        "print(var_result.summary())\n",
        "\n",
        "# Проверка остатков модели\n",
        "print(\"\\nДиагностика остатков модели:\")\n",
        "print(\"-\" * 40)\n",
        "\n",
        "# Тест Дарбина-Ватсона на автокорреляцию\n",
        "dw_stat = durbin_watson(var_result.resid)\n",
        "print(\"Статистика Дарбина-Ватсона для остатков:\")\n",
        "for i, col in enumerate(df.columns):\n",
        "    print(f\"  {col}: {dw_stat[i]:.4f}\")\n",
        "\n",
        "# Нормальность остатков\n",
        "from scipy.stats import jarque_bera\n",
        "\n",
        "print(\"\\nТест Харке-Бера на нормальность остатков:\")\n",
        "for i, col in enumerate(df.columns):\n",
        "    jb_stat, jb_pvalue = jarque_bera(var_result.resid[:, i])\n",
        "    print(f\"  {col}: статистика={jb_stat:.4f}, p-value={jb_pvalue:.4f}\")"
      ],
      "metadata": {
        "id": "o7Nymu25XcZc"
      },
      "id": "o7Nymu25XcZc",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Прогнозирование с помощью VAR модели"
      ],
      "metadata": {
        "id": "OrVRsQwaXeUV"
      },
      "id": "OrVRsQwaXeUV"
    },
    {
      "cell_type": "code",
      "source": [
        "def forecast_var(model, steps, last_observations):\n",
        "    \"\"\"\n",
        "    Прогнозирование с помощью VAR модели\n",
        "    \"\"\"\n",
        "    forecast = model.forecast(last_observations, steps)\n",
        "    return forecast\n",
        "\n",
        "# Прогнозирование на тестовой выборке\n",
        "forecast_steps = len(test_data)\n",
        "last_train_obs = train_data.values[-optimal_lag:]\n",
        "\n",
        "# Прогноз\n",
        "forecast = forecast_var(var_result, forecast_steps, last_train_obs)\n",
        "forecast_index = test_data.index\n",
        "forecast_df = pd.DataFrame(forecast, index=forecast_index, columns=df.columns)\n",
        "\n",
        "# Обратное преобразование (если применяли дифференцирование)\n",
        "if not all(stationarity_results.values()):\n",
        "    # Для обратного преобразования нужны исходные данные\n",
        "    last_values = df.iloc[train_size-1:train_size].values\n",
        "\n",
        "    # Восстанавливаем уровни\n",
        "    forecast_levels = forecast_df.copy()\n",
        "    for i, col in enumerate(df.columns):\n",
        "        if not stationarity_results.get(col, False):\n",
        "            forecast_levels[col] = last_values[0, i] + forecast_df[col].cumsum()\n",
        "\n",
        "    forecast_final = forecast_levels\n",
        "    test_final = df.iloc[train_size:train_size+forecast_steps]\n",
        "else:\n",
        "    forecast_final = forecast_df\n",
        "    test_final = test_data\n",
        "\n",
        "# Визуализация прогнозов\n",
        "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
        "for i, (col, ax) in enumerate(zip(df.columns, axes.flatten())):\n",
        "    # Обучающие данные\n",
        "    ax.plot(train_data.index, train_data[col] if col in train_data.columns else\n",
        "            df[col].iloc[:train_size],\n",
        "            color=colors[i], alpha=0.7, label='Обучающие данные')\n",
        "\n",
        "    # Тестовые данные\n",
        "    ax.plot(test_final.index, test_final[col],\n",
        "            color=colors[i], linewidth=2, label='Фактические значения')\n",
        "\n",
        "    # Прогноз\n",
        "    ax.plot(forecast_final.index, forecast_final[col],\n",
        "            color='black', linestyle='--', linewidth=2, label='Прогноз VAR')\n",
        "\n",
        "    # Доверительный интервал (упрощенный)\n",
        "    forecast_std = forecast_final[col].std()\n",
        "    ax.fill_between(forecast_final.index,\n",
        "                    forecast_final[col] - 1.96 * forecast_std,\n",
        "                    forecast_final[col] + 1.96 * forecast_std,\n",
        "                    alpha=0.2, color='gray', label='95% доверительный интервал')\n",
        "\n",
        "    ax.set_title(f'Прогноз для {col}', fontsize=14)\n",
        "    ax.set_xlabel('Дата')\n",
        "    ax.set_ylabel('Значение')\n",
        "    ax.legend()\n",
        "    ax.grid(True, alpha=0.3)\n",
        "\n",
        "plt.suptitle('Прогнозирование многомерного временного ряда с помощью VAR', fontsize=16)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Оценка качества прогноза\n",
        "print(\"=\" * 60)\n",
        "print(\"Оценка качества прогноза\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "metrics = pd.DataFrame(index=df.columns, columns=['RMSE', 'MAE', 'MAPE', 'R²'])\n",
        "\n",
        "for col in df.columns:\n",
        "    y_true = test_final[col].values\n",
        "    y_pred = forecast_final[col].values\n",
        "\n",
        "    # Вычисление метрик\n",
        "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
        "    mae = mean_absolute_error(y_true, y_pred)\n",
        "    mape = np.mean(np.abs((y_true - y_pred) / (y_true + 1e-10))) * 100\n",
        "\n",
        "    # R-квадрат\n",
        "    ss_res = np.sum((y_true - y_pred) ** 2)\n",
        "    ss_tot = np.sum((y_true - np.mean(y_true)) ** 2)\n",
        "    r2 = 1 - (ss_res / (ss_tot + 1e-10))\n",
        "\n",
        "    metrics.loc[col] = [rmse, mae, mape, r2]\n",
        "\n",
        "print(\"\\nМетрики качества прогноза:\")\n",
        "print(metrics.round(4))"
      ],
      "metadata": {
        "id": "nCmE69M8XeB5"
      },
      "id": "nCmE69M8XeB5",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Анализ импульсных откликов"
      ],
      "metadata": {
        "id": "w6t67A28Ximo"
      },
      "id": "w6t67A28Ximo"
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_impulse_responses(var_model, periods=20, plot_variance_decomposition=False):\n",
        "    \"\"\"\n",
        "    Визуализация импульсных откликов VAR модели\n",
        "    \"\"\"\n",
        "    # Импульсные отклики\n",
        "    irf = var_model.irf(periods=periods)\n",
        "\n",
        "    # Графики импульсных откликов\n",
        "    fig, axes = plt.subplots(n_series, n_series, figsize=(16, 12))\n",
        "\n",
        "    for i in range(n_series):\n",
        "        for j in range(n_series):\n",
        "            ax = axes[i, j]\n",
        "            ax.plot(irf.irfs[:, i, j], linewidth=2)\n",
        "            ax.axhline(y=0, color='red', linestyle='--', alpha=0.5)\n",
        "            ax.set_title(f'{df.columns[j]} → {df.columns[i]}', fontsize=10)\n",
        "            ax.grid(True, alpha=0.3)\n",
        "\n",
        "            if i == n_series - 1:\n",
        "                ax.set_xlabel('Период')\n",
        "            if j == 0:\n",
        "                ax.set_ylabel('Отклик')\n",
        "\n",
        "    plt.suptitle('Импульсные отклики VAR модели', fontsize=16)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    # Декомпозиция дисперсии ошибки прогноза\n",
        "    if plot_variance_decomposition:\n",
        "        print(\"\\nДекомпозиция дисперсии ошибки прогноза:\")\n",
        "        print(\"-\" * 50)\n",
        "\n",
        "        # Декомпозиция на горизонте 10 периодов\n",
        "        fevd = irf.fevd(periods=10)\n",
        "        fevd_df = pd.DataFrame(\n",
        "            fevd.decomp.mean(axis=0),  # Среднее по горизонтам\n",
        "            index=df.columns,\n",
        "            columns=df.columns\n",
        "        )\n",
        "\n",
        "        print(\"\\nСредний вклад в ошибку прогноза (%):\")\n",
        "        print((fevd_df * 100).round(2))\n",
        "\n",
        "        # Визуализация декомпозиции дисперсии\n",
        "        fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
        "        for idx, (col, ax) in enumerate(zip(df.columns, axes.flatten())):\n",
        "            contributions = fevd.decomp[:, idx, :]\n",
        "            periods_range = range(1, len(contributions) + 1)\n",
        "\n",
        "            bottom = np.zeros(len(contributions))\n",
        "            for i, comp_col in enumerate(df.columns):\n",
        "                ax.fill_between(periods_range, bottom, bottom + contributions[:, i],\n",
        "                               label=comp_col, alpha=0.7)\n",
        "                bottom += contributions[:, i]\n",
        "\n",
        "            ax.set_title(f'Декомпозиция дисперсии для {col}', fontsize=12)\n",
        "            ax.set_xlabel('Горизонт прогноза')\n",
        "            ax.set_ylabel('Доля дисперсии')\n",
        "            ax.legend(loc='upper right', fontsize=8)\n",
        "            ax.grid(True, alpha=0.3)\n",
        "\n",
        "        plt.suptitle('Декомпозиция дисперсии ошибки прогноза', fontsize=16)\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "    return irf\n",
        "\n",
        "# Построение импульсных откликов\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"Анализ импульсных откликов\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "irf_results = plot_impulse_responses(var_result, periods=15, plot_variance_decomposition=True)"
      ],
      "metadata": {
        "id": "VvzgdAg9Xl5T"
      },
      "id": "VvzgdAg9Xl5T",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Тест причинности по Грейнджеру"
      ],
      "metadata": {
        "id": "OvzTRlenXqIl"
      },
      "id": "OvzTRlenXqIl"
    },
    {
      "cell_type": "code",
      "source": [
        "def granger_causality_test(df, max_lag=5, significance_level=0.05):\n",
        "    \"\"\"\n",
        "    Проверка причинно-следственных связей по Грейнджеру\n",
        "    \"\"\"\n",
        "    n_vars = len(df.columns)\n",
        "    causality_matrix = pd.DataFrame(np.zeros((n_vars, n_vars)),\n",
        "                                    index=df.columns,\n",
        "                                    columns=df.columns)\n",
        "\n",
        "    print(\"Тест причинности по Грейнджеру:\")\n",
        "    print(\"-\" * 50)\n",
        "\n",
        "    for cause in df.columns:\n",
        "        for effect in df.columns:\n",
        "            if cause != effect:\n",
        "                try:\n",
        "                    test_result = grangercausalitytests(\n",
        "                        df[[effect, cause]],\n",
        "                        maxlag=max_lag,\n",
        "                        verbose=False\n",
        "                    )\n",
        "\n",
        "                    # Берем p-value для оптимального лага\n",
        "                    p_values = [test_result[i+1][0]['ssr_chi2test'][1]\n",
        "                               for i in range(max_lag)]\n",
        "                    min_p_value = min(p_values)\n",
        "\n",
        "                    causality_matrix.loc[effect, cause] = min_p_value\n",
        "\n",
        "                except Exception as e:\n",
        "                    causality_matrix.loc[effect, cause] = 1.0\n",
        "\n",
        "    # Визуализация матрицы причинности\n",
        "    plt.figure(figsize=(10, 8))\n",
        "    mask = np.zeros_like(causality_matrix.values, dtype=bool)\n",
        "    np.fill_diagonal(mask, True)\n",
        "\n",
        "    sns.heatmap(causality_matrix,\n",
        "                mask=mask,\n",
        "                annot=True,\n",
        "                fmt=\".3f\",\n",
        "                cmap='RdYlGn_r',\n",
        "                center=significance_level,\n",
        "                square=True,\n",
        "                cbar_kws={'label': 'p-value'},\n",
        "                linewidths=1)\n",
        "\n",
        "    plt.title('Матрица причинности по Грейнджеру\\n(ячейки: p-value для H0: нет причинности)',\n",
        "              fontsize=14)\n",
        "    plt.xlabel('Причина (Granger-causes)')\n",
        "    plt.ylabel('Следствие (is caused by)')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    # Интерпретация результатов\n",
        "    print(\"\\nЗначимые причинно-следственные связи (p-value < 0.05):\")\n",
        "    print(\"-\" * 50)\n",
        "\n",
        "    significant_links = []\n",
        "    for cause in df.columns:\n",
        "        for effect in df.columns:\n",
        "            if cause != effect:\n",
        "                p_val = causality_matrix.loc[effect, cause]\n",
        "                if p_val < significance_level:\n",
        "                    significant_links.append((cause, effect, p_val))\n",
        "                    print(f\"{cause} → {effect}: p-value = {p_val:.4f}\")\n",
        "\n",
        "    if not significant_links:\n",
        "        print(\"Не обнаружено значимых причинно-следственных связей\")\n",
        "\n",
        "    return causality_matrix, significant_links\n",
        "\n",
        "# Проведение теста Грейнджера\n",
        "causality_matrix, significant_links = granger_causality_test(df_stationary, max_lag=5)"
      ],
      "metadata": {
        "id": "FpJeG7ClXuf5"
      },
      "id": "FpJeG7ClXuf5",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Проверка коинтеграции"
      ],
      "metadata": {
        "id": "5khOltb2XwgG"
      },
      "id": "5khOltb2XwgG"
    },
    {
      "cell_type": "code",
      "source": [
        "def check_cointegration(df, significance_level=0.05):\n",
        "    \"\"\"\n",
        "    Проверка коинтеграции многомерного временного ряда\n",
        "    \"\"\"\n",
        "    print(\"Проверка коинтеграции (тест Йохансена):\")\n",
        "    print(\"-\" * 50)\n",
        "\n",
        "    # Тест Йохансена\n",
        "    coint_test = coint_johansen(df, det_order=0, k_ar_diff=1)\n",
        "\n",
        "    # Критические значения\n",
        "    trace_critical_values = coint_test.cvt[:, 0]\n",
        "    max_eigen_critical_values = coint_test.cvm[:, 0]\n",
        "\n",
        "    print(f\"Количество рядов: {len(df.columns)}\")\n",
        "    print(f\"\\nСобственные значения: {coint_test.eig}\")\n",
        "\n",
        "    print(\"\\nРезультаты trace теста:\")\n",
        "    print(\"Ранг  Собст.знач  Trace-стат   Крит.знач 10%  Гипотеза\")\n",
        "    print(\"-\" * 60)\n",
        "\n",
        "    for i in range(len(df.columns)):\n",
        "        hypothesis = \"Нет коинтеграции\" if i == 0 else f\"Ранг ≤ {i}\"\n",
        "        trace_stat = coint_test.lr1[i]\n",
        "        crit_value = trace_critical_values[i]\n",
        "        is_significant = trace_stat > crit_value\n",
        "\n",
        "        print(f\"{i:4d}  {coint_test.eig[i]:10.4f}  {trace_stat:10.2f}  {crit_value:13.2f}  \"\n",
        "              f\"{'Отвергаем' if is_significant else 'Принимаем'} {hypothesis}\")\n",
        "\n",
        "    print(\"\\nРезультаты максимального собственного значения:\")\n",
        "    print(\"Ранг  Собст.знач  Max-стат    Крит.знач 10%  Гипотеза\")\n",
        "    print(\"-\" * 60)\n",
        "\n",
        "    for i in range(len(df.columns)):\n",
        "        hypothesis = \"Нет коинтеграции\" if i == 0 else f\"Ранг ≤ {i}\"\n",
        "        max_stat = coint_test.lr2[i]\n",
        "        crit_value = max_eigen_critical_values[i]\n",
        "        is_significant = max_stat > crit_value\n",
        "\n",
        "        print(f\"{i:4d}  {coint_test.eig[i]:10.4f}  {max_stat:9.2f}  {crit_value:13.2f}  \"\n",
        "              f\"{'Отвергаем' if is_significant else 'Принимаем'} {hypothesis}\")\n",
        "\n",
        "    # Определение ранга коинтеграции\n",
        "    rank_trace = 0\n",
        "    rank_max = 0\n",
        "\n",
        "    for i in range(len(df.columns)):\n",
        "        if coint_test.lr1[i] > trace_critical_values[i]:\n",
        "            rank_trace = i + 1\n",
        "        if coint_test.lr2[i] > max_eigen_critical_values[i]:\n",
        "            rank_max = i + 1\n",
        "\n",
        "    print(f\"\\nРанг коинтеграции (по trace тесту): {rank_trace}\")\n",
        "    print(f\"Ранг коинтеграции (по max eigen тесту): {rank_max}\")\n",
        "\n",
        "    if rank_trace > 0 or rank_max > 0:\n",
        "        print(\"\\nОбнаружена коинтеграция! Ряды имеют долгосрочное равновесное соотношение.\")\n",
        "        print(\"Коинтегрирующие векторы:\")\n",
        "        print(coint_test.evec[:, :max(rank_trace, rank_max)])\n",
        "    else:\n",
        "        print(\"\\nКоинтеграция не обнаружена.\")\n",
        "\n",
        "    return coint_test, max(rank_trace, rank_max)\n",
        "\n",
        "# Проверка коинтеграции\n",
        "coint_result, coint_rank = check_cointegration(df)"
      ],
      "metadata": {
        "id": "8t8e1c2IX0ZW"
      },
      "id": "8t8e1c2IX0ZW",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Задания для самостоятельной работы"
      ],
      "metadata": {
        "id": "5CZNmZgLX3cl"
      },
      "id": "5CZNmZgLX3cl"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Задание 1: VAR с экзогенными переменными (VARX)\n",
        "\n",
        "Задача: Расширьте базовую VAR модель, добавив экзогенные переменные (VARX). Сгенерируйте данные с 2 эндогенными и 2 экзогенными переменными.\n",
        "\n",
        "Требования:\n",
        "\n",
        "    Сгенерируйте многомерный ряд с:\n",
        "\n",
        "        2 эндогенными переменными (зависят от своих лагов и друг от друга)\n",
        "\n",
        "        2 экзогенными переменными (влияют на эндогенные, но не наоборот)\n",
        "\n",
        "    Реализуйте VARX модель\n",
        "\n",
        "    Сравните прогнозную способность VAR и VARX\n",
        "\n",
        "    Проанализируйте влияние экзогенных переменных на эндогенные"
      ],
      "metadata": {
        "id": "vcL8DGUWX9NF"
      },
      "id": "vcL8DGUWX9NF"
    },
    {
      "cell_type": "code",
      "source": [
        "# Шаблон для решения задания 1\n",
        "def generate_varx_data():\n",
        "    \"\"\"Генерация данных для VARX модели\"\"\"\n",
        "    pass\n",
        "\n",
        "def fit_varx_model():\n",
        "    \"\"\"Обучение VARX модели\"\"\"\n",
        "    pass"
      ],
      "metadata": {
        "id": "xK2j8lJ9YF2o"
      },
      "id": "xK2j8lJ9YF2o",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Задание 2: Байесовская VAR (BVAR)\n",
        "\n",
        "Задача: Реализуйте Байесовскую версию VAR модели с априорными распределениями коэффициентов.\n",
        "\n",
        "Требования:\n",
        "\n",
        "    Изучите концепции байесовского подхода:\n",
        "\n",
        "        Minnesota prior\n",
        "\n",
        "        Normal-Wishart prior\n",
        "\n",
        "    Реализуйте BVAR с использованием:\n",
        "\n",
        "        Марковских цепей Монте-Карло (MCMC)\n",
        "\n",
        "        Вариационного вывода\n",
        "\n",
        "    Сравните с классической VAR:\n",
        "\n",
        "        Точность прогнозов\n",
        "\n",
        "        Интервалы прогнозирования\n",
        "\n",
        "        Устойчивость к переобучению"
      ],
      "metadata": {
        "id": "YIrJ8hIkYITX"
      },
      "id": "YIrJ8hIkYITX"
    },
    {
      "cell_type": "code",
      "source": [
        "# Шаблон для решения задания 2\n",
        "class BayesianVAR:\n",
        "    \"\"\"Реализация Байесовской VAR\"\"\"\n",
        "    pass"
      ],
      "metadata": {
        "id": "uWrgObOSYLG-"
      },
      "id": "uWrgObOSYLG-",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}